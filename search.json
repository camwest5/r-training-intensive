[
  {
    "objectID": "project_gallery.html",
    "href": "project_gallery.html",
    "title": "Project Gallery",
    "section": "",
    "text": "Goalkeepers and their heights\n\n\n\n\n\n\nCameron West and Stéphane Guillou\n\n\nMay 16, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Projects/details.html",
    "href": "Projects/details.html",
    "title": "Overview",
    "section": "",
    "text": "The best way to learn is by doing. That’s why, over the these three days, you are tasked with analysing, visualising and reporting on a set of data!\nRoughly 50% of our intensive is dedicated to working on the project. Working in groups of 2-4, you’ll need to use the techniques we learn to draw some observations about your chosen dataset.\nThe end goal will be a quick fire (low stakes) one-minute presentation with a dashboard to complement.\nSee the datasets page for the data and below for submission details.",
    "crumbs": [
      "Workshops",
      "The Project",
      "Overview"
    ]
  },
  {
    "objectID": "Projects/details.html#project-outline",
    "href": "Projects/details.html#project-outline",
    "title": "Overview",
    "section": "Project outline",
    "text": "Project outline\nThere are a few key requirements for the project, but otherwise it’s up to you!\n\nAnalyse a dataset and create some visualisations\nPut together a final dashboard-style report. Anything from a powerpoint slide to an interactive dashboard will do!\nDeliver a quick fire one-minute presentation with your group\n\nWe’ll have 5 sessions during the intensive days to work on the project, just shy of six hours. The goal of these sessions is twofold\n\nTo work on the project, analysing data and creating visualisations\nTo dive deeper into the content, perfect for questions and conversations\n\nWhile you’ll be working in groups, everyone should practise analysing and visualising the data. We recommend distributing roles amongst the group, maybe looking at different variables or different presentation formats.\nYou’re welcome to use the project time however you’d like. Below is a rough guide if you’re unsure:\n\n\n\n\n\n\n\nSession\nRecommendation\n\n\n\n\nTuesday afternoon\nPick a dataset and play with the data\n\n\nWednesday morning\nMore exploratory analysis, consider dividing roles amongst group\n\n\nWednesday afternoon\nStart collecting initial visualisations and preparing format (e.g. dashboard)\n\n\nThursday morning\nContinue analysing and creating visualisations\n\n\nThursday afternoon\nPolish up results\n\n\n\nThe presentations will be during Thursday’s final session at 2:50pm.\nGood luck!",
    "crumbs": [
      "Workshops",
      "The Project",
      "Overview"
    ]
  },
  {
    "objectID": "Projects/details.html#design-and-submissions",
    "href": "Projects/details.html#design-and-submissions",
    "title": "Overview",
    "section": "Design and submissions",
    "text": "Design and submissions\nWe’ve put together an example dashboard which you’re welcome to start from. Download the code to have a look at our example. You can also see a gallery of examples on Quarto’s website.\n\nUploading the submission\nBelow are two ways you can upload your visualisations.\nYou should consider where your dashboard gets its data from. Our repo has all datasets in the data_sources folder, so you have two options:\n\nInclude the data in your dashboard’s folder that you upload.\nUse the relative reference ../../data_sources/data_set_of_your_choice.csv to access the data on our repo\n\nWe’ve used the second option in the example project.\nWhen you are ready to upload, you have two options:\n\nUpload dashboard to GitHub\nThis is the advanced way of doing things - we recommend this way, because it’ll show you a good insight into using GitHub.\n\nCreate a GitHub account and log in\nCreate a fork of our r-training-intensive repository. This is a copy of the repo in your account, changes will not automatically affect the main repo. Leave all settings unchanged.\nCreate a folder for your dashboard inside the Projects directory\n\nGo into the Projects folder, and click Add file \\(\\rightarrow\\) Create new file. This will be your folder.\nGive it a name but no content.\nPress Commit changes....\n\nUpload your files\n\nGo into your new folder and click Add file \\(\\rightarrow\\) Upload files.\nUpload your dashboard and associated files.\nPress Commit changes.\n\nMerge your repo with ours\n\nPress &lt;&gt; Code (top left) to go back to the top level of the repo\nPress Contribute \\(\\rightarrow\\) Open pull request to request merging your files into the main repo\nPress Create pull request when you’re ready.\nIf you need to make further changes, no worries - the pull request will stay up to date with these until approved or closed.\n\n\nGive it a go if you can!\nIf there’s any issues, we’ll leave a comment for you to fix up the merge and we’ll approve it when ready.\n\n\nUpload dashboard to Teams\nIf you’re having issues with the GitHub approach, we can upload it for you. Just put your folder with the dashboard into our Teams folder.",
    "crumbs": [
      "Workshops",
      "The Project",
      "Overview"
    ]
  },
  {
    "objectID": "Workshops/index.html",
    "href": "Workshops/index.html",
    "title": "Workshops",
    "section": "",
    "text": "Over these three days we’ll cover six sessions of content:\n\n\n\nSession\nDescription\n\n\n\n\nThe Fundamentals\nThe basics of R. Variables, functions and packages.\n\n\nData processing\nImporting, manipulating and analysing data with dplyr\n\n\nVisualisation\nCreating visualisations of our data with ggplot2\n\n\nSharing and Publishing\nUsing GitHub for sharing and version control, as well as quarto for publishing dashboards and websites.\n\n\nStatistics\nDescriptive and inferential statistics, with some regressions and hypothesis testing.\n\n\nProgramming Essentials\nR tools everyone should know. Conditionals, loops and functions.\n\n\n\nThese content sessions are pretty packed, and we won’t have too much time to deviate. That’s why we’ll also have five project sessions - see Project Overview for details. You’re welcome to ask lengthier questions and play around there!",
    "crumbs": [
      "Workshops"
    ]
  },
  {
    "objectID": "Workshops/5 - Statistics.html",
    "href": "Workshops/5 - Statistics.html",
    "title": "Statistics",
    "section": "",
    "text": "This session is aimed as an overview of how to perform some statistical modelling with R. It is an R workshop, not a statistics workshop - if you’d like to better understand the statistical models, or need help deciding what’s best for you, please consult a statistics resource or contact a statistician.\nIn this session, we’ll cover\nWe’ll be working from our “Players2024” dataset. After downloading it and putting it in your data folder, to bring it in and clean it up,\nlibrary(dplyr)\nplayers &lt;- read.csv(\"data/Players2024.csv\")\nplayers &lt;- players %&gt;% filter(positions != \"Missing\", height_cm &gt; 100)\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union",
    "crumbs": [
      "Workshops",
      "Statistics"
    ]
  },
  {
    "objectID": "Workshops/5 - Statistics.html#descriptive-statistics",
    "href": "Workshops/5 - Statistics.html#descriptive-statistics",
    "title": "Statistics",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nWe’ll start with sample size. To calculate the number of non-empty observations in a column, say the numeric variable players$height_cm, we use the length() function\n\nlength(players$height_cm)\n\n[1] 5932\n\n\nWe can compute measures of central tendancy similarly. The average value is given by\n\nmean(players$height_cm)\n\n[1] 183.0413\n\n\nand the median by\n\nmedian(players$height_cm)\n\n[1] 183\n\n\n\nMeasures of variance\nWe can also compute measures of variance. The minimum and maximum are as expected\n\nmin(players$height_cm)\n\n[1] 160\n\nmax(players$height_cm)\n\n[1] 206\n\n\nThe function range() yields both\n\nrange(players$height_cm)\n\n[1] 160 206\n\n\nSo the actual range, i.e. the difference, is\n\ndiff(range(players$height_cm))\n\n[1] 46\n\n\nQuartiles are given by quantile() and the inter-quartile range (IQR) by IQR():\n\nquantile(players$height_cm)\n\n  0%  25%  50%  75% 100% \n 160  178  183  188  206 \n\nIQR(players$height_cm)\n\n[1] 10\n\n\nA column’s standard deviation and variance are given by\n\nsd(players$height_cm)\n\n[1] 6.838736\n\nvar(players$height_cm)\n\n[1] 46.76832\n\n\nAll together, you can see a nice statistical summary with\n\nsummary(players$height_cm)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    160     178     183     183     188     206 \n\n\n\n\nMeasures of correlation\nIf you’ve got two numeric variables, you might want to examine covariance and correlation. These indicate how strongly the variables are linearly related. We’ll need to use the players$age variable as well.\nThe covariance between “height_cm” and “age” is\n\ncov(players$height_cm, players$age)\n\n[1] 0.5126608\n\n\nSimilarly, we can find the Pearson correlation coefficient between two columns.\n\ncor(players$height_cm, players$age)\n\n[1] 0.01682598\n\n\nYou can also specify “kendall” or “spearman” for their respective correlation coefficients\n\ncor(players$height_cm, players$age, method = \"kendall\")\n\n[1] 0.005417946\n\ncor(players$height_cm, players$age, method = \"spearman\")\n\n[1] 0.007604345\n\n\n\n\nReminder about groupbys\nBefore we move to inferential statistics, it’s worth reiterating the power of groupbys discussed in the second workshop.\nTo group by a specific variable, like “positions”, we use\n\nplayers %&gt;% \n    group_by(positions)\n\n# A tibble: 5,932 × 7\n# Groups:   positions [4]\n   name                birth_date height_cm positions  nationality   age club   \n   &lt;chr&gt;               &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;  \n 1 James Milner        1986-01-04       175 Midfield   England        38 Bright…\n 2 Anastasios Tsokanis 1991-05-02       176 Midfield   Greece         33 Volou …\n 3 Jonas Hofmann       1992-07-14       176 Midfield   Germany        32 Bayer …\n 4 Pepe Reina          1982-08-31       188 Goalkeeper Spain          42 Calcio…\n 5 Lionel Carole       1991-04-12       180 Defender   France         33 Kayser…\n 6 Ludovic Butelle     1983-04-03       188 Goalkeeper France         41 Stade …\n 7 Daley Blind         1990-03-09       180 Defender   Netherlands    34 Girona…\n 8 Craig Gordon        1982-12-31       193 Goalkeeper Scotland       41 Heart …\n 9 Dimitrios Sotiriou  1987-09-13       185 Goalkeeper Greece         37 Omilos…\n10 Alessio Cragno      1994-06-28       184 Goalkeeper Italy          30 Associ…\n# ℹ 5,922 more rows\n\n\nBy applying our statistics to the group_by object, we’ll apply them to every variable for each position.\n\nplayers %&gt;% \n    group_by(positions) %&gt;% \n    summarise(mean_height = mean(height_cm))\n\n# A tibble: 4 × 2\n  positions  mean_height\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Attack            181.\n2 Defender          184.\n3 Goalkeeper        191.\n4 Midfield          180.",
    "crumbs": [
      "Workshops",
      "Statistics"
    ]
  },
  {
    "objectID": "Workshops/5 - Statistics.html#inferential-statistics",
    "href": "Workshops/5 - Statistics.html#inferential-statistics",
    "title": "Statistics",
    "section": "Inferential Statistics",
    "text": "Inferential Statistics\nWhile descriptive statistics describes the data definitively, inferential statistics aim to produce models for extrapolating conlusions.\n\nSimple linear regressions\nLeast-squares regression for two sets of measurements can be performed with the function lm. Recall that linear regressions have the mathematical form\n\\[ Y = β_1 X + β_0 \\]\nand we use the regression tool to estimate the parameters \\(β_0\\,,β_1\\). We can equivalently say that \\(Y \\sim X\\), which is what R takes in\n\nlm(\"height_cm ~ age\", players)\n\n\nCall:\nlm(formula = \"height_cm ~ age\", data = players)\n\nCoefficients:\n(Intercept)          age  \n  182.38260      0.02583  \n\n\nIf we store this as a variable, we can then produce a summary of the results\n\nmodel &lt;- lm(\"height_cm ~ age\", players)\nsummary(model)\n\n\nCall:\nlm(formula = \"height_cm ~ age\", data = players)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-23.028  -5.028   0.075   4.978  23.075 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 182.38260    0.51599 353.460   &lt;2e-16 ***\nage           0.02583    0.01993   1.296    0.195    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.838 on 5930 degrees of freedom\nMultiple R-squared:  0.0002831, Adjusted R-squared:  0.0001145 \nF-statistic: 1.679 on 1 and 5930 DF,  p-value: 0.1951\n\n\nIf you want to get specific parameters out, we can index with $:\n\nsummary(model)$r.squared\n\n[1] 0.0002831136\n\n\nThat’s a pretty shocking fit.\n\nPlotting it\nNaturally, you’d want to plot this. We’ll need to use techniques from the visualisation session. Let’s import ggplot2\n\nlibrary(ggplot2)\n\nStart by making a scatterplot of the data,\n\nggplot(players, aes(x = height_cm, y = age)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThen, you’ll need to plot the regression as a line. For reference,\n\\[ y = \\text{slope}\\times x + \\text{intercept}\\]\nSo\n\nb0 &lt;- model$coefficients[1]\nb1 &lt;- model$coefficients[2]\n\nggplot(players, aes(x = age, y = height_cm)) + \n    geom_point() + \n    geom_abline(intercept = b0, slope = b1)\n\n\n\n\n\n\n\n\n\n\n\n\\(t\\)-tests\nWe can also perform \\(t\\)-tests. Typically, these are performed to examine the statistical signficance of a difference between two samples’ means. Let’s examine whether that earlier groupby result for is accurate for heights, specifically, are goalkeepers taller than non-goalkeepers?\nLet’s start by creating a new column with the values\n\n\n\nFALSE\nNon-goalkeeper\n\n\nTRUE\nGoalkeeper\n\n\n\n\nplayers &lt;- players %&gt;% \n  mutate(gk = positions == \"Goalkeeper\")\n\nThe \\(t\\)-test’s goal is to check whether \\(\\text{height\\_cm}\\) depends on \\(\\text{gk}\\), so the formula is \\(\\text{height\\_cm}\\sim\\text{gk}\\). This is given to the t.test function:\n\nt.test(height_cm ~ gk, data = players)\n\n\n    Welch Two Sample t-test\n\ndata:  height_cm by gk\nt = -48.817, df = 1274.4, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group FALSE and group TRUE is not equal to 0\n95 percent confidence interval:\n -9.036644 -8.338391\nsample estimates:\nmean in group FALSE  mean in group TRUE \n           181.9810            190.6685 \n\n\nYielding a p-value of \\(p&lt;2.2\\times10^{-16}\\), indicating that the null-hypothesis (heights are the same) is extremely unlikely.\nTo visualise this result, it might be helpful to produce a histogram of the heights\n\nggplot(players, \n       aes(x = height_cm, fill = gk)) + \n  geom_histogram(bins = 24)\n\n\n\n\n\n\n\n\n\n\nANOVAs\nWhat about the means of the other three? We could use an ANOVA to examine them. We use the aov() function for this.\nLet’s start by making a new dataset without goalkeepers\n\nno_gk &lt;- players %&gt;% filter(gk == FALSE)\n\nNext, we save the analysis of variance results\n\nres_aov &lt;- aov(height_cm ~ positions, data = no_gk)\n\nAnd examine them with summary()\n\nsummary(res_aov)\n\n              Df Sum Sq Mean Sq F value Pr(&gt;F)    \npositions      2  15470    7735   199.7 &lt;2e-16 ***\nResiduals   5205 201552      39                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEven without goalkeepers included, it looks like their positions are not all independent of height.\n\n\n\\(\\chi^2\\) tests\n\\(χ^2\\) tests are useful for examining the relationship of categorical variables by comparing the frequencies of each. Often, you’d use this if you can make a contingency table.\nWe only have one useful categorical variable here, “positions” (the others have too many unique values), so we’ll need to create another. Let’s see if there’s a relationship between players’ positions and names with the letter “a”.\nMake a binary column for players with the letter “a” in their names. To do this, we need to apply a string method to all the columns in the dataframe as follows\n\nplayers &lt;- players %&gt;%\n  mutate(a_in_name = grepl(\"a\", name))\n\n\nThe grepl function perform pattern matching: it checks if the pattern \"a\" is inside the values in name.\n\nLet’s cross tabulate positions with this new column\n\ntable(players$positions, players$a_in_name)\n\n            \n             FALSE TRUE\n  Attack       291 1280\n  Defender     355 1606\n  Goalkeeper   149  575\n  Midfield     312 1364\n\n\nThe \\(χ^2\\) test’s job is to examine whether players’ positions depend on the presence of “a” in their name. To evaluate it we need to send the contingency table in:\n\nchisq.test(table(players$positions, players$a_in_name))\n\n\n    Pearson's Chi-squared test\n\ndata:  table(players$positions, players$a_in_name)\nX-squared = 2.1808, df = 3, p-value = 0.5357\n\n\nAs expected, there is no signifcant relationship. A simple bar plot can help us here\n\nggplot(players,\n       aes(x = positions, fill = a_in_name)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nIf we use the position = \"fill\" parameter to geom_bar, we’ll see each as a proportion\n\nggplot(players,\n       aes(x = positions, fill = a_in_name)) + \n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\nIt looks as though the proportions are much the same.\n\n\nGeneralised linear models\nWe’ll finish by looking at Generalised Linear Models. The distributions they include are\n\nBinomial\nPoisson\nGaussian (Normal)\nGamma\nInverse Gaussian\nA few quasi options\n\nWe’ll use the binomial option to create logistic regressions.\nLogistic regressions examine the distribution of binary data. For us, we can compare the heights of goalkeepers vs non-goalkeepers again.\nNow, we can model this column with height. We’ll do the same as our \\(t\\)-test case, but this time we need to specify that family = binomial to ensure we’ll get a logistic:\n\nres_logistic &lt;- glm(gk ~ height_cm, family = binomial, data = players)\n\nWe can take a look at the results with\n\nsummary(res_logistic)\n\n\nCall:\nglm(formula = gk ~ height_cm, family = binomial, data = players)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -53.23360    1.92714  -27.62   &lt;2e-16 ***\nheight_cm     0.27448    0.01019   26.94   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 4401.4  on 5931  degrees of freedom\nResidual deviance: 3167.0  on 5930  degrees of freedom\nAIC: 3171\n\nNumber of Fisher Scoring iterations: 6\n\n\nAnd we can then visualise it with ggplot2. We need to make another variable, because we need to replace TRUE \\(\\rightarrow\\) 1 and FALSE \\(\\rightarrow\\) 0 for the plot.\n\nplayers &lt;- players %&gt;% mutate(gk_numeric = as.numeric(gk))\n\nNow we can plot the logistic regression. The fitted values (on the \\(y\\)-axis) are stored in res_logistic$fitted.values, but there are no provided \\(x\\)-values - these come from the players dataset. Use geom_point() for the data and geom_line() for the fit:\n\nggplot(players, aes(x = height_cm, y = gk_numeric)) + \n  geom_point() + \n  geom_line(aes(y = res_logistic$fitted.values))",
    "crumbs": [
      "Workshops",
      "Statistics"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html",
    "href": "Workshops/3 - Visualisation.html",
    "title": "Visualisation",
    "section": "",
    "text": "During this session, you will:",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html#installing-ggplot2",
    "href": "Workshops/3 - Visualisation.html#installing-ggplot2",
    "title": "Visualisation",
    "section": "Installing ggplot2",
    "text": "Installing ggplot2\nWe first need to make sure we have the ggplot2 package available on our computer. We can use the “Install” button in the “Packages” pane, or we can execute this command in the console: install.packages(\"ggplot2\")\nYou only need to install a package once, but you need to load it every time you start a new R session.\nWe will write ggplot2 code more comfortably in a script. Feel free to continue using the script from previous sessions, or create a new one about visualisations.\nWe can straight away load the package into the library by adding this command to our script and executing it:\n\nlibrary(ggplot2)",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html#finding-help",
    "href": "Workshops/3 - Visualisation.html#finding-help",
    "title": "Visualisation",
    "section": "Finding help",
    "text": "Finding help\nWe are going to work with different datasets that come with the ggplot2 package. For any dataset or function doubts that you might have, don’t forget the three ways to bring up a help page:\n\nthe command: ?functionname\nthe keyboard shortcut: press F1 after writing a function name\nthe search box in the Help pane\n\n\nIntroducing ggplot2\nThe R package ggplot2 was developed by Hadley Wickham with the objective of creating a grammar of graphics for categorical data (in 2007). It is based on the book The Grammar of Graphics Developed by Leland Wilkinson (first edition published in 1999).\nIt is now part of the group of data science packages called Tidyverse.",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html#the-components-of-the-grammar-of-graphics",
    "href": "Workshops/3 - Visualisation.html#the-components-of-the-grammar-of-graphics",
    "title": "Visualisation",
    "section": "The components of the Grammar of Graphics",
    "text": "The components of the Grammar of Graphics\nThe Grammar of Graphics is based on the idea that you can build every graph from the same few components.\nThe components are:\n\nData\nMapping\nStatistics\nScales\nGeometries\nFacets\nCoordinates\nTheme\n\nIn this introductory session, we will mainly focus on the data, the mapping, the statistics, the geometries and the theme.",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html#ggplot2s-three-essential-components",
    "href": "Workshops/3 - Visualisation.html#ggplot2s-three-essential-components",
    "title": "Visualisation",
    "section": "ggplot2’s three essential components",
    "text": "ggplot2’s three essential components\nIn ggplot2, the 3 main components that we usually have to provide are:\n\nWhere the data comes from,\nthe aesthetic mappings, and\na geometry.\n\nFor our first example, let’s use the msleep dataset (from the ggplot2 package), which contains data about mammals’ sleeping patterns.\n\nYou can find out about the dataset with ?msleep.\n\nLet’s start with specifying where the data comes from in the ggplot() function:\n\nggplot(data = msleep)\n\n\n\n\n\n\n\n\nThis is not very interesting. We need to tell ggplot2 what we want to visualise, by mapping aesthetic elements (like our axes) to variables from the data. We want to visualise how common different conservations statuses are, so let’s associate the right variable to the x axis:\n\nggplot(data = msleep,\n       mapping = aes(x = conservation))\n\n\n\n\n\n\n\n\nggplot2 has done what we asked it to do: the conservation variable is on the x axis. But nothing is shown on the plot area, because we haven’t defined how to represent the data, with a geometry_* function:\n\nggplot(data = msleep,\n       mapping = aes(x = conservation)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nNow we have a useful plot: we can see that a lot of animals in this dataset don’t have a conservation status, and that “least concern” is the next most common value.\nWe can see our three essential elements in the code:\n\nthe data comes from the msleep object;\nthe variable conservation is mapped to the aesthetic x (i.e. the x axis);\nthe geometry is \"bar\", for “bar chart”.\n\nHere, we don’t need to specify what variable is associated to the y axis, as the “bar” geometry automatically does a count of the different values in the conservation variable. That is what statistics are applied automatically to the data.\n\nIn ggplot2, each geometry has default statistics, so we often don’t need to specify which stats we want to use. We could use a stat_*() function instead of a geom_*() function, but most people start with the geometry (and let ggplot2 pick the default statistics that are applied).",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html#line-plots",
    "href": "Workshops/3 - Visualisation.html#line-plots",
    "title": "Visualisation",
    "section": "Line plots",
    "text": "Line plots\nLet’s have a look at another dataset: the economics dataset from the US. Learn more about it with ?economics, and have a peak at its structure with:\n\nstr(economics)\n\nspc_tbl_ [574 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ date    : Date[1:574], format: \"1967-07-01\" \"1967-08-01\" ...\n $ pce     : num [1:574] 507 510 516 512 517 ...\n $ pop     : num [1:574] 198712 198911 199113 199311 199498 ...\n $ psavert : num [1:574] 12.6 12.6 11.9 12.9 12.8 11.8 11.7 12.3 11.7 12.3 ...\n $ uempmed : num [1:574] 4.5 4.7 4.6 4.9 4.7 4.8 5.1 4.5 4.1 4.6 ...\n $ unemploy: num [1:574] 2944 2945 2958 3143 3066 ...\n\n\nDo you think that unemployment is stable over the years? Let’s have a look with a line plot, often used to visualise time series:\n\nggplot(data = economics,\n       mapping = aes(x = date,\n                     y = unemploy)) + \n    geom_line()\n\n\n\n\n\n\n\n\nLet’s go through our essential elements once more:\n\nThe ggplot() function initialises a ggplot object. In it, we declare the input data frame and specify the set of plot aesthetics used throughout all layers of our plot;\nThe aes() function groups our mappings of aesthetics to variables;\nThe geom_&lt;...&gt;() function specifies what geometric element we want to use.",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html#scatterplots",
    "href": "Workshops/3 - Visualisation.html#scatterplots",
    "title": "Visualisation",
    "section": "Scatterplots",
    "text": "Scatterplots\nScatterplots are often used to look at the relationship between two variables. Let’s try it with a new dataset: mpg (which stands for “miles per gallon”), a dataset about fuel efficiency of different models of cars.\n\n?mpg\nstr(mpg)\n\nDo you think that big engines use fuel more efficiently than small engines?\nWe can focus on two variables:\n\ndispl: a car’s engine size, in litres.\nhwy: a car’s fuel efficiency on the highway, in miles per gallon.\n\nFor the geometry, we now have use “points”:\n\nggplot(data = mpg,\n       mapping = aes(x = displ,\n                     y = hwy)) +\n    geom_point()\n\n\n\n\n\n\n\n\nNotice how the points seem to be aligned on a grid? That’s because the data was rounded. If we want to better visualise the density of points, we can use the “count” geometry, which makes the dots bigger when data points have the same x and y values:\n\nggplot(data = mpg,\n       mapping = aes(x = displ,\n                     y = hwy)) +\n    geom_count()\n\n\n\n\n\n\n\n\nAlternatively, we can avoid overlapping of points by using the “jitter” geometry, which gives the points a little shake:\n\nggplot(data = mpg,\n       mapping = aes(x = displ,\n                     y = hwy)) +\n    geom_jitter()\n\n\n\n\n\n\n\n\nEven though the position of the dots does not match exactly the original x and y values, it does help visualise densities better.\nThe plot shows a negative relationship between engine size (displ) and fuel efficiency (hwy). In other words, cars with big engines use more fuel. Does this confirm or refute your hypothesis about fuel efficiency and engine size?\nHowever, we can see some outliers. We need to find out more about our data.",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html#adding-aesthetics",
    "href": "Workshops/3 - Visualisation.html#adding-aesthetics",
    "title": "Visualisation",
    "section": "Adding aesthetics",
    "text": "Adding aesthetics\nWe can highlight the “class” factor by adding a new aesthetic:\n\nggplot(data = mpg,\n       mapping = aes(x = displ,\n                     y = hwy,\n                     colour = class)) +\n    geom_jitter()\n\n\n\n\n\n\n\n\nIt seems that two-seaters are more fuel efficient than other cars with a similar engine size, which can be explained by the lower weight of the car. The general trend starts to make more sense!\nWe now know how to create a simple scatterplot, and how to visualise extra variables. But how can we better represent a correlation?",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html#trend-lines",
    "href": "Workshops/3 - Visualisation.html#trend-lines",
    "title": "Visualisation",
    "section": "Trend lines",
    "text": "Trend lines\nA trend line can be created with the geom_smooth() function:\n\nggplot(mpg,\n       aes(x = displ,\n           y = hwy)) +\n    geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nWe stopped using the argument names because we know in which order they appear: first the data, then the mapping of aesthetics. Let’s save ourselves some typing from now on!\n\nThe console shows you what function / formula was used to draw the trend line. This is important information, as there are countless ways to do that. To better understand what happens in the background, open the function’s help page and notice that the default value for the method argument is “NULL”. Read up on how it automatically picks a suitable method depending on the sample size, in the “Arguments” section.\nWant a linear trend line instead? Add the argument method = \"lm\" to your function:\n\nggplot(mpg,\n       aes(x = displ,\n           y = hwy)) +\n    geom_smooth(method = \"lm\")",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html#layering",
    "href": "Workshops/3 - Visualisation.html#layering",
    "title": "Visualisation",
    "section": "Layering",
    "text": "Layering\nA trend line is usually displayed on top of the scatterplot. How can we combine several layers? We can string them with the + operator:\n\nggplot(mpg,\n       aes(x = displ,\n           y = hwy)) + \n    geom_point() +\n    geom_smooth()\n\n\n\n\n\n\n\n\n\nThe order of the functions matters: the points will be drawn before the trend line, which is probably what you’re after.",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html#the-colour-aesthetic",
    "href": "Workshops/3 - Visualisation.html#the-colour-aesthetic",
    "title": "Visualisation",
    "section": "The colour aesthetic",
    "text": "The colour aesthetic\nWe can once again add some information to our visualisation by mapping the class variable to the colour aesthetic:\n\nggplot(mpg,\n       aes(x = displ,\n           y = hwy)) + \n    geom_point(aes(colour = class)) + \n    geom_smooth()\n\n\n\n\n\n\n\n\nChallenge 1 – where should aesthetics be defined?\nTake the last plot we created:\n\nggplot(mpg,\n       aes(x = displ,\n           y = hwy)) + \n    geom_point(aes(colour = class)) + \n    geom_smooth()\n\nWhat would happen if you moved the colour = class aesthetic from the geometry function to the ggplot() call?\nDifferent geometries can also have their own mappings that overwrite the defaults. If you place mappings in a geom_* function, ggplot2 will treat them as local mappings for the layer. It will use these mappings to extend or overwrite the global mappings for that layer only. This makes it possible to display different aesthetics in different layers.",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html#saving-a-plot",
    "href": "Workshops/3 - Visualisation.html#saving-a-plot",
    "title": "Visualisation",
    "section": "Saving a plot",
    "text": "Saving a plot\nLike your visualisation? You can export it with the “Export” menu in the “Plots” pane.\n\nBuilding a document or a slideshow? You can copy it straight to your clipboard, and paste it into it.\nA PDF is a good, quick option to export an easily shareable file with vector graphics. Try for example the “A5” size, the “Landscape” orientation, and save it into your “plots” directory.\nMore options are available in the “Save as image…” option. PNG is a good compressed format for graphics, but if you want to further customise your visualisation in a different program, use SVG or EPS, which are vector formats. (Try to open an SVG file in Inkscape for example.)\n\nTo save the last plot with a command, you can use the ggsave() function:\n\nggsave(filename = \"plots/fuel_efficiency.png\")\n\nThis is great to automate the export process for each plot in your script, but ggsave() also has extra options, like setting the DPI, which is useful for getting the right resolution for a specific use. For example, to export a plot for your presentation:\n\nggsave(filename = \"plots/fuel_efficiency.png\", dpi = \"screen\")\n\n\nSaving a .svg file with requires installing the svglite package. This packages seems so work best installing in a fresh R session (Session &gt; Restart R) from source install.packages(\"svglite\", type = \"source\"). Then load the library library(svglite) rerun your code including loading previous libraries (ggplot2 etc.) and now saving a plot with a .svg extension should work!\n\nChallenge 2 – add a variable and a smooth line\nLet’s use a similar approach to what we did with the mpg dataset.\nTake our previous unemployment visualisation, but represented with points this time:\n\nggplot(economics,\n       aes(x = date,\n           y = unemploy)) + \n    geom_point()\n\nHow could we:\n\nAdd a smooth line for the number of unemployed people. Are there any interesting arguments that could make the smoother more useful?\nColour the points according to the median duration of unemployment (see ?economics)\n\n\nggplot(economics,\n       aes(x = date,\n           y = unemploy)) + \n    geom_point(aes(colour = uempmed)) +\n    geom_smooth()\n\n\n\n\n\n\n\n\n\nSee how the legend changes depending on the type of data mapped to the colour aesthetic? (i.e. categorical vs continuous)\n\nThis default “trend line” is not particularly useful. We could make it follow the data more closely by using the span argument. The closer to 0, the closer to the data the smoother will be:\n\nggplot(economics,\n       aes(x = date,\n           y = unemploy)) + \n    geom_point(aes(colour = uempmed)) +\n    geom_smooth(span = 0.1)\n\n\n\n\n\n\n\n\nYou can now see why this is called a “smoother”: we can fit a smooth curve to data that varies a lot.\nTo further refine our visualisation, we could visualise the unemployment rate rather than the number of unemployed people, by calculating it straight into our code:\n\nggplot(economics,\n       aes(x = date,\n           y = unemploy / pop)) + \n    geom_point(aes(colour = uempmed)) +\n    geom_smooth(span = 0.1)\n\n\n\n\n\n\n\n\nThe early 1980s recession now seems to have had a more significant impact on unemployment than the Global Financial Crisis of 2007-2008.",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html#bar-charts-and-ordered-factors",
    "href": "Workshops/3 - Visualisation.html#bar-charts-and-ordered-factors",
    "title": "Visualisation",
    "section": "Bar charts and ordered factors",
    "text": "Bar charts and ordered factors\nLet’s use the diamonds dataset now. The diamonds dataset comes with ggplot2 and contains information about ~54,000 diamonds, including the price, carat, colour, clarity, and cut quality of each diamond.\nLet’s have a look at the data:\n\ndiamonds\nsummary(diamonds)\n?diamonds\n\nBack to bar charts. Consider a basic bar chart, as drawn with geom_bar(). The following chart displays the total number of diamonds in the diamonds dataset, grouped by cut:\n\nggplot(diamonds,\n       aes(x = cut)) + \n    geom_bar()\n\n\n\n\n\n\n\n\nThe chart shows that more diamonds are available with high quality cuts than with low quality cuts.\ncut is an ordered factor, which you can confirm by printing it to the console:\n\nhead(diamonds$cut)\n\n[1] Ideal     Premium   Good      Premium   Good      Very Good\nLevels: Fair &lt; Good &lt; Very Good &lt; Premium &lt; Ideal\n\n\nSee how ggplot2 respects that order in the bar chart?\n\nCustomising a plot\nLet’s see how we can customise our bar chart’s look.\n\nChange a geometry’s default colour\nFirst, we can pick our favourite colour in geom_bar():\n\nggplot(diamonds,\n       aes(x = cut)) + \n    geom_bar(fill = \"tomato\")\n\n\n\n\n\n\n\n\nIf you are curious about what colour names exist in R, you can use the colours() function. Alernatively, you can use any hex value like “#760daa”.\n\n\n\nChange labels\nWe can also modify labels with the labs() function to make our plot more self-explanatory:\n\nggplot(diamonds,\n       aes(x = cut)) + \n    geom_bar(fill = \"tomato\") +\n    labs(title = \"Where are the bad ones?\",\n         x = \"Quality of the cut\",\n         y = \"Number of diamonds\")\n\n\n\n\n\n\n\n\nLet’s have a look at what labs() can do:\n\n?labs\n\nIt can edit the title, the subtitle, the x and y axes labels, and the caption.\n\nRemember that captions and titles are better sorted out in the publication itself, especially for accessibility reasons (e.g. to help with screen readers).\n\n\n\nHorizontal bar charts\nFor a horizontal bar chart, we can map the cut variable to the y aesthetic instead of x. But remember to also change your labels around!\n\nggplot(diamonds,\n       aes(y = cut)) + # switch here...\n  geom_bar(fill = \"tomato\") +\n  labs(title = \"Where are the bad ones?\",\n       y = \"Quality of the cut\", # ...but also here!\n       x = \"Number of diamonds\") # ...and here!\n\n\n\n\n\n\n\n\nThis is particularly helpful when long category names overlap under the x axis.\n\n\nBuilt-in themes\nThe theme() function allows us to really get into the details of our plot’s look, but some theme_*() functions make it easy to apply a built-in theme, like theme_bw():\n\nggplot(diamonds,\n       aes(y = cut)) + \n  geom_bar(fill = \"tomato\") +\n  labs(title = \"Where are the bad ones?\",\n       y = \"Quality of the cut\",\n       x = \"Number of diamonds\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nTry theme_minimal() as well, and if you want more options, install the ggthemes package!",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html#interactive-visualisations",
    "href": "Workshops/3 - Visualisation.html#interactive-visualisations",
    "title": "Visualisation",
    "section": "Interactive visualisations",
    "text": "Interactive visualisations\nPlotly is a package that allows creating interactive visualisation. A nifty aspect of it is that it can directly convert most static ggplot2 visualisations to interactive HTML visualisations.\nAfter installing the package, you can convert our mpg visualisation by saving it as an object, and passing it to the ggplotly() function:\n\nstatic_plot &lt;- ggplot(mpg,\n                      aes(x = displ,\n                          y = hwy)) + \n  geom_jitter(aes(colour = class)) + \n  geom_smooth()\nlibrary(plotly)\nggplotly(static_plot)\n\n\n\n\n\nWe can now use our mouse to hover over points and see the associated data, turn series off and on, and draw rectangles to zoom in.\nThis kind of visualisation is a good way to expose extra data through the tooltips. For example, associating the “manufacturer” and “model” variables to “label” aesthetics in the ggplot2 command won’t show that information on the static visualisation (unless labelling geometry is used), but it will be included in the plotly tooltip:\n\nstatic_plot &lt;- ggplot(mpg,\n                      aes(x = displ,\n                          y = hwy)) + \n  geom_jitter(aes(colour = class,\n                  label = manufacturer,\n                  label2 = model)) + \n  geom_smooth()\nlibrary(plotly)\nggplotly(static_plot)",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/3 - Visualisation.html#further-resources",
    "href": "Workshops/3 - Visualisation.html#further-resources",
    "title": "Visualisation",
    "section": "Further resources",
    "text": "Further resources\n\nggplot2 cheatsheet\nOfficial ggplot2 documentation\nOfficial ggplot2 website\nChapter on data visualisation in the book R for Data Science\nFrom Data to Viz, a website to explore different visualisations and the code that generates them\nSelva Prabhakaran’s r-statistics.co section on ggplot2\nCoding Club’s data visualisation tutorial\nSTHDA’s ggplot2 essentials\nLear more about plotly and exploratory data analysis with the book Interactive web-based data visualization with R, plotly, and shiny",
    "crumbs": [
      "Workshops",
      "Visualisation"
    ]
  },
  {
    "objectID": "Workshops/1 - Fundamentals.html",
    "href": "Workshops/1 - Fundamentals.html",
    "title": "The Fundamentals",
    "section": "",
    "text": "In this workshop, we will learn about:",
    "crumbs": [
      "Workshops",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "Workshops/1 - Fundamentals.html#maths-and-objects",
    "href": "Workshops/1 - Fundamentals.html#maths-and-objects",
    "title": "The Fundamentals",
    "section": "Maths and objects",
    "text": "Maths and objects\nThe console (by default at the bottom left in RStudio) is where most of the action happens. In the console, we can use R interactively. We write a command and then execute it by pressing Enter.\nIn its most basic use, R can be a calculator. Try executing the following commands:\n\n10 - 2\n\n[1] 8\n\n3 * 4\n\n[1] 12\n\n2 + 10 / 5\n\n[1] 4\n\n\nThose symbols are called “binary operators”: we can use them to multiply, divide, add and subtract. Once we execute the command (the “input”), we can see the result in the console (the “output”).\nWhat if we want to keep reusing the same value? We can store data by creating objects, and assigning values to them with the assignment operator &lt;-:\n\nnum1 &lt;- 42\nnum2 &lt;- num1 / 9\nnum2\n\n[1] 4.666667\n\n\n\nYou can use the shortcut Alt+- to type the assignement operator quicker.\n\nWe can also store text data:\n\nsentence &lt;- \"Hello World!\"\nsentence\n\n[1] \"Hello World!\"\n\n\nYou should now see your objects listed in you environment pane (top right).\nAs you can see, you can store different kinds of data as objects. If you want to store text data (a “string of characters”), you have to use quotes around them.\n\nYou can recall your recent commands with the up arrow, which is especially useful to correct typos or slightly modify a long command.\n\nUsing the console is great to test things and quickly run commands and get outputs. However, if we want to store our process and refine our code as we go over several sessions, it is best to work with a script. Let’s do a bit more setting up of our project.",
    "crumbs": [
      "Workshops",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "Workshops/1 - Fundamentals.html#create-a-folder-structure",
    "href": "Workshops/1 - Fundamentals.html#create-a-folder-structure",
    "title": "The Fundamentals",
    "section": "Create a folder structure",
    "text": "Create a folder structure\nTo keep it tidy, we are creating 3 folders in our project directory:\n\nscripts\ndata\nplots\n\nYou can do that with the “New Folder” button in the “Files” pane (bottom right of the window).",
    "crumbs": [
      "Workshops",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "Workshops/1 - Fundamentals.html#scripts",
    "href": "Workshops/1 - Fundamentals.html#scripts",
    "title": "The Fundamentals",
    "section": "Scripts",
    "text": "Scripts\nScripts are simple text files that contain R code. They are useful for:\n\nsaving a set of commands for later use (and executing it in one click)\nmaking research reproducible\nmaking writing and reading code more comfortable\ndocumenting the code with comments, and\nsharing your work with peers\n\nLet’s create a new R script with the menu: File &gt; New File &gt; R Script. (This can also be done with the first icon in the toolbar, or with the shortcut Ctrl+Shift+N.)\nThis opens our fourth pane in the top left of RStudio: the source pane.\n\nComments\nWe should start with a couple of comments, to document our script. Comments start with #, and will be ignored by R:\n# Description: Introduction to R and RStudio\n# Author: &lt;your name&gt;\n# Date: &lt;today's date&gt;\n\n\nSyntax highlighting\nNow, add some commands to your script:\n\nnum1 &lt;- 42\nnum2 &lt;- num1 / 9\n\nNotice the colours? This is called syntax highlighting. This is one of the many ways RStudio makes it more comfortable to work with R. The code is more readable when working in a script.\n\nWhile editing your script, you can run the current command (or the selected block of code) by using Ctrl+Enter. Remember to save your script regularly with the shortcut Ctrl+S. You can find more shortcuts with Alt+Shift+K, or the menu “Tools &gt; Keyboard Shortcuts Help”.",
    "crumbs": [
      "Workshops",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "Workshops/1 - Fundamentals.html#functions",
    "href": "Workshops/1 - Fundamentals.html#functions",
    "title": "The Fundamentals",
    "section": "Functions",
    "text": "Functions\nAn R function is a little program that does a particular job. It usually looks like this:\n&lt;functionname&gt;(&lt;argument(s)&gt;)\nArguments tell the function what to do. Some functions don’t need arguments, others need one or several, but they always need the parentheses after their name.\nFor example, try running the following command:\n\nround(num2)\n\n[1] 5\n\n\nThe round() function rounds a number to the closest integer. The only argument we give it is num2, the number we want to round.\n\nIf you scroll back to the top of your console, you will now be able to spot functions in the text.\n\n\nHelp\nWhat if we want to learn more about a function?\nThere are two main ways to find help about a specific function in RStudio:\n\nthe shortcut command: ?functionname\nthe keyboard shortcut: press F1 with your cursor in a function name (you can do this by simply clicking on the function name)\n\nLet’s look through the documentation for the round() function:\n?round\nAs you can see, different functions might share the same documentation page.\nThere is quite a lot of information in a function’s documentation, but the most important bits are:\n\nDescription: general description of the function(s)\nUsage: overview of what syntax can be used\nArguments: description of what each argument is\nExamples: some examples that demonstrate what is possible\n\nSee how the round() function has a second argument available? Try this now:\n\nround(num2, digits = 2)\n\n[1] 4.67\n\n\nWe can change the default behaviour of the function by telling it how many digits we want after the decimal point, using the argument digits. And if we use the arguments in order, we don’t need to name them:\n\nround(num2, 2)\n\n[1] 4.67\n\n\nTo group values together in a single object, use the c() function.\nc() combines the arguments into a vector. In other words, it takes any number of arguments (hence the ...), and stores all those values together, as one single object. For example, let’s store the ages of our pet dogs in a new object:\n\nages &lt;- c(4, 10, 2, NA, 3)\n\n\nYou can store missing data as NA.\n\nWe can now reuse this vector, and calculate their human age:\n\nages * 7\n\n[1] 28 70 14 NA 21\n\n\nR can create visualisations with functions too. Try a bar plot of your dogs’ ages with the barplot() function:\n\nbarplot(ages)\n\n\n\n\n\n\n\n\nWe can customise the plot with a title and some colours, for example:\n\nbarplot(ages, main = \"How old are my dogs?\", col = \"pink\")\n\n\n\n\n\n\n\n\n\nChallenge 1 – Finding help\nUse the help pages to find out what these functions do, and try executing commands with them:\n\nrep.int()\nmean()\nrm()\n\nrep.int() creates vectors like c(), but it is designed to easily replicate values. For example, if you find something very funny:\n\nrep.int(\"Ha!\", 30)\n\n [1] \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\"\n[13] \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\"\n[25] \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\"\n\n\nThe next function, mean(), returns the mean of a vector of numbers:\n\nmean(ages)\n\n[1] NA\n\n\nWhat happened there?\nWe have an NA value in the vector, which means the function can’t tell what the mean is. If we want to change this default behaviour, we can use an extra argument: na.rm, which stands for “remove NAs”.\n\nmean(ages, na.rm = TRUE)\n\n[1] 4.75\n\n\n\nIn our last command, if we hadn’t named the na.rm argument, R would have understood TRUE to be the value for the trim argument!\n\nrm() removes an object from your environment (remove() and rm() point to the same function). For example:\n\nrm(num1)\n\n\nR does not check if you are sure you want to remove something! As a programming language, it does what you ask it to do, which means you might have to be more careful. But you’ll see later on that, when working with scripts, this is less of a problem.\n\nLet’s do some more complex operations by combining two functions:\nls() returns a character vector: it contains the names of all the objects in the current environment (i.e. the objects we created in this R session). Notice that this function doesn’t require us to provide any argument, but we still need to write the parentheses to run the function.\nIs there a way we could combine ls() with rm()?\nYou can remove all the objects in the environment by using ls() as the value for the list argument:\n\nrm(list = ls())\n\nWe are nesting a function inside another one. More precisely, we are using the output of the ls() function as the value passed on to the list argument in the rm() function.\n\n\n\nIncomplete functions\nIf you don’t finish a function, by leaving off the last bracket ) for example, the line of code won’t necessarily give you an error, but it won’t work very well. If you forget to include that last bracket, R will run the code, and then wait for further instructions before giving you an output. This will appear as a + in the console like so:\n&gt; round(1.23\n+\nIf you try to give any further instructions to R, it will likely just continue giving you + symbols, and not return anything. To stop this, click on the console and press the Esc key on your keyboard.\n\n\nMore help\nWe’ve practised how to find help about functions we know the name of. What if we don’t know what the function is called? Or if we want general help about R?\n\nThe function help.start() is a good starting point: it opens a browser of official R help.\nIf you want to search for a word in all the documentation, you can use the ?? syntax. For example, try executing ??anova.\nFinally, you will often go to your web browser and search for a particular question, or a specific error message: most times, there already is an answer somewhere on the Internet. The challenge is to ask the right question!",
    "crumbs": [
      "Workshops",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "Workshops/1 - Fundamentals.html#import-data",
    "href": "Workshops/1 - Fundamentals.html#import-data",
    "title": "The Fundamentals",
    "section": "Import data",
    "text": "Import data\nLet’s bring in some data. Download our gapminder dataset and save it in the data/ folder you just created.\nOnce you’ve got the data, use the read.csv() command to bring it into R:\ngapminder &lt;- read.csv(\"data/gapminder.csv\")\nWhat do you think they do? Describe each one in detail, and try executing them.",
    "crumbs": [
      "Workshops",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "Workshops/1 - Fundamentals.html#explore-data",
    "href": "Workshops/1 - Fundamentals.html#explore-data",
    "title": "The Fundamentals",
    "section": "Explore data",
    "text": "Explore data\nWe have downloaded a CSV file from the Internet, and read it into an object called gapminder.\nYou can type the name of your new object to print it to screen:\n\ngapminder\n\nThat’s a lot of lines printed to your console. To have a look at the first few lines only, we can use the head() function:\n\nhead(gapminder)\n\n      country year      pop continent lifeExp gdpPercap\n1 Afghanistan 1952  8425333      Asia  28.801  779.4453\n2 Afghanistan 1957  9240934      Asia  30.332  820.8530\n3 Afghanistan 1962 10267083      Asia  31.997  853.1007\n4 Afghanistan 1967 11537966      Asia  34.020  836.1971\n5 Afghanistan 1972 13079460      Asia  36.088  739.9811\n6 Afghanistan 1977 14880372      Asia  38.438  786.1134\n\n\nNow let’s use a few functions to learn more about our dataset:\n\nclass(gapminder) # what kind of object is it stored as?\n\n[1] \"data.frame\"\n\nnrow(gapminder) # how many rows?\n\n[1] 1704\n\nncol(gapminder) # how many columns?\n\n[1] 6\n\ndim(gapminder) # rows and columns\n\n[1] 1704    6\n\nnames(gapminder) # variable names\n\n[1] \"country\"   \"year\"      \"pop\"       \"continent\" \"lifeExp\"   \"gdpPercap\"\n\n\nAll the information we just saw (and more) is available with one single function:\n\nstr(gapminder) # general structure\n\n'data.frame':   1704 obs. of  6 variables:\n $ country  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...\n $ pop      : num  8425333 9240934 10267083 11537966 13079460 ...\n $ continent: chr  \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n $ lifeExp  : num  28.8 30.3 32 34 36.1 ...\n $ gdpPercap: num  779 821 853 836 740 ...\n\n\n\nThe RStudio’s environment panel already shows us some of that information (click on the blue arrow next to the object name).\n\nAnd to explore the data in a viewer, click on the table icon next to the object in the Environment pane.\nThis viewer allows you to explore your data by scrolling through, searching terms, filtering rows and sorting the data. Remember that it is only a viewer: it will never modify your original object.\n\nNotice that RStudio actually runs the View() function. Feel free to use that instead of clicking on the button, but note that the case matters: using a lowercase “v” will yield an error.\n\nTo see summary statistics for each of our variables, you can use the summary() function:\n\nsummary(gapminder)\n\n   country               year           pop             continent        \n Length:1704        Min.   :1952   Min.   :6.001e+04   Length:1704       \n Class :character   1st Qu.:1966   1st Qu.:2.794e+06   Class :character  \n Mode  :character   Median :1980   Median :7.024e+06   Mode  :character  \n                    Mean   :1980   Mean   :2.960e+07                     \n                    3rd Qu.:1993   3rd Qu.:1.959e+07                     \n                    Max.   :2007   Max.   :1.319e+09                     \n    lifeExp        gdpPercap       \n Min.   :23.60   Min.   :   241.2  \n 1st Qu.:48.20   1st Qu.:  1202.1  \n Median :60.71   Median :  3531.8  \n Mean   :59.47   Mean   :  7215.3  \n 3rd Qu.:70.85   3rd Qu.:  9325.5  \n Max.   :82.60   Max.   :113523.1  \n\n\nNotice how categorical and numerical variables are handled differently?\nLet’s now plot the relationship between GDP per capita and life expectancy:\n\nplot(gapminder$gdpPercap, gapminder$lifeExp,\n     xlab = \"GDP per capita (USD)\",\n     ylab = \"Life expectancy (years)\")\n\n\n\n\n\n\n\n\n\nFor more on visualisations, we will later dive into the popular ggplot2 package.\n\nFinally, let’s fit a linear model to see how strongly correlated the two variables are:\n\nlinear_model &lt;- lm(gapminder$lifeExp ~ gapminder$gdpPercap)\nsummary(linear_model)\n\n\nCall:\nlm(formula = gapminder$lifeExp ~ gapminder$gdpPercap)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-82.754  -7.758   2.176   8.225  18.426 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         5.396e+01  3.150e-01  171.29   &lt;2e-16 ***\ngapminder$gdpPercap 7.649e-04  2.579e-05   29.66   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.49 on 1702 degrees of freedom\nMultiple R-squared:  0.3407,    Adjusted R-squared:  0.3403 \nF-statistic: 879.6 on 1 and 1702 DF,  p-value: &lt; 2.2e-16\n\n\nThe P-value suggests that there is a strong relationship between the two.",
    "crumbs": [
      "Workshops",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "Workshops/1 - Fundamentals.html#packages",
    "href": "Workshops/1 - Fundamentals.html#packages",
    "title": "The Fundamentals",
    "section": "Packages",
    "text": "Packages\nPackages add functionalities to R and RStudio. There are more than 21000 available.\nYou can see the list of installed packages in your “Packages” tab, or by using the library() function without any argument.\nWe are going to install a package called “skimr”. We can do that in the Packages tab:\n\nOpen the “Packages” tab (bottom-right pane)\nClick the “Install” button\nSearch for “skimr”\nClick “Install”\n\n\nNotice how it runs an install.packages() command in the console? You can use that too.\n\nIf I now try running the command skim(), I get an error. That’s because, even though the package is installed, I need to load it every time I start a new R session. The library() function does that. Let’s load the package, and use the skim() function to get an augmented summary of our gapminder dataset:\n\nlibrary(skimr) # load the package into your library\nskim(gapminder) # use a function from the package\n\n\nData summary\n\n\nName\ngapminder\n\n\nNumber of rows\n1704\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncountry\n0\n1\n4\n24\n0\n142\n0\n\n\ncontinent\n0\n1\n4\n8\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1\n1979.50\n17.27\n1952.00\n1965.75\n1979.50\n1993.25\n2007.0\n▇▅▅▅▇\n\n\npop\n0\n1\n29601212.33\n106157896.75\n60011.00\n2793664.00\n7023595.50\n19585221.75\n1318683096.0\n▇▁▁▁▁\n\n\nlifeExp\n0\n1\n59.47\n12.92\n23.60\n48.20\n60.71\n70.85\n82.6\n▁▆▇▇▇\n\n\ngdpPercap\n0\n1\n7215.33\n9857.45\n241.17\n1202.06\n3531.85\n9325.46\n113523.1\n▇▁▁▁▁\n\n\n\n\n\nThis function provides further summary statistics, and even displays a small histogram for each numeric variable.\n\nPackages are essential to use R to its full potential, by making the most out of what other users have created and shared with the community. To get an idea of some of the most important packages depending on your field of study, you can start with the CRAN Task Tiews.\n\n\nChallenge 3\nFor a bit of fun:\n\nTry installing the package “cowsay” and using its function say().\nHave a look at the documentation and the package’s website.\nCan you make Clippy say the current time?\nCan you make a chicken say “bok” a thousand times? (Hint: look at the paste() function and its arguments.)",
    "crumbs": [
      "Workshops",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "Workshops/1 - Fundamentals.html#closing-rstudio",
    "href": "Workshops/1 - Fundamentals.html#closing-rstudio",
    "title": "The Fundamentals",
    "section": "Closing RStudio",
    "text": "Closing RStudio\nYou can close RStudio after making sure that you saved your script.\nWhen you create a project in RStudio, you create an .Rproj file that gathers information about the state of your project. When you close RStudio, you have the option to save your workspace (i.e. the objects in your environment) as an .Rdata file. The .Rdata file is used to reload your workspace when you open your project again. Projects also bring back whatever source file (e.g. script) you had open, and your command history. You will find your command history in the “History” tab (upper right panel): all the commands that we used should be in there.\nIf you have a script that contains all your work, it is a good idea not to save your workspace: it makes it less likely to run into errors because of accumulating objects. The script will allow you to get back to where you left it, by executing all the clearly laid-out steps.\nThe console, on the other hand, only shows a brand new R session when you reopen RStudio. Sessions are not persistent, and a clean one is started when you open your project again, which is why you have to load any extra package your work requires again with the library() function.",
    "crumbs": [
      "Workshops",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "Workshops/1 - Fundamentals.html#resources",
    "href": "Workshops/1 - Fundamentals.html#resources",
    "title": "The Fundamentals",
    "section": "Resources",
    "text": "Resources\n\nWe have a compilation of resources for the rest of your R learning\nAnd a cheatsheet of main terms and concepts for R",
    "crumbs": [
      "Workshops",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Intro and Setting Up",
    "section": "",
    "text": "Welcome to our three-day R training intensive! By Thursday afternoon, you’ll have learnt the R skills to manipulate, visualise and present data. We’ll spend roughly half the time learning content, and half the time working on a project in groups.\nAs we set up, there’s a few things to do, if you haven’t already\n\nInstall the software\nIntroduce yourself to your table\nJoin our Teams channel\nRegister your attendance",
    "crumbs": [
      "Workshops",
      "Intro and Setting Up"
    ]
  },
  {
    "objectID": "setup.html#overview",
    "href": "setup.html#overview",
    "title": "Intro and Setting Up",
    "section": "",
    "text": "Welcome to our three-day R training intensive! By Thursday afternoon, you’ll have learnt the R skills to manipulate, visualise and present data. We’ll spend roughly half the time learning content, and half the time working on a project in groups.\nAs we set up, there’s a few things to do, if you haven’t already\n\nInstall the software\nIntroduce yourself to your table\nJoin our Teams channel\nRegister your attendance",
    "crumbs": [
      "Workshops",
      "Intro and Setting Up"
    ]
  },
  {
    "objectID": "setup.html#r-rstudio",
    "href": "setup.html#r-rstudio",
    "title": "Intro and Setting Up",
    "section": "R + RStudio",
    "text": "R + RStudio\nThe R programming language is a language used for calculations, statistics, visualisations and many more data science tasks.\nRStudio is an open source Integrated Development Environment (IDE) for R, which means it provides many features on top of R to make it easier to write and run code.\nR’s main strong points are:\n\nOpen Source: you can install it anywhere and adapt it to your needs;\nReproducibility: makes an analysis repeatable by detailing the process in a script;\nCustomisable: being a programming language, you can create your own custom tools;\nLarge datasets: it can handle very large datasets (certainly well beyond the row limitations of Excel, and even further using HPCs and other tricks);\nDiverse ecosystem: packages allow you to extend R for thousands of different analyses.\n\nThe learning curve will be steeper than point-and-click tools, but as far as programming languages go, R is more user-friendly than others.\n\nInstallation\nFor this course, you need to have both R and RStudio installed (installation instructions).",
    "crumbs": [
      "Workshops",
      "Intro and Setting Up"
    ]
  },
  {
    "objectID": "setup.html#r-projects",
    "href": "setup.html#r-projects",
    "title": "Intro and Setting Up",
    "section": "R Projects",
    "text": "R Projects\nLet’s first create a new project:\n\nClick the “File” menu button (top left corner), then “New Project”\nClick “New Directory”\nClick “New Project”\nIn “Directory name”, type the name of your project, for example “YYYY-MM-DD_rstudio-intro”\nBrowse and select a folder where to locate your project (~ is your home directory). For example, a folder called “r-projects”.\nClick the “Create Project” button\n\n\nR Projects make your work with R more straight forward, as they allow you to segregate your different projects in separate folders. You can create a .Rproj file in a new directory or an existing directory that already has R code and data. Everything then happens by default in this directory. The .Rproj file stores information about your project options, and allows you to go straight back to your work.",
    "crumbs": [
      "Workshops",
      "Intro and Setting Up"
    ]
  },
  {
    "objectID": "Workshops/2 - Data processing.html",
    "href": "Workshops/2 - Data processing.html",
    "title": "Preparing data for analysis",
    "section": "",
    "text": "In this hands-on session, we will use the dplyr package to transform your data.\nSpecifically, you will learn how to explore, filter, reorganise and process a dataframe with the following verbs:\n\nselect(): pick variables\nfilter(): pick observations\narrange(): reorder observations\nmutate(): create new variables\nsummarise(): collapse to a single summary\ngroup_by(): change the scope of function",
    "crumbs": [
      "Workshops",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "Workshops/2 - Data processing.html#what-are-we-going-to-learn",
    "href": "Workshops/2 - Data processing.html#what-are-we-going-to-learn",
    "title": "Preparing data for analysis",
    "section": "",
    "text": "In this hands-on session, we will use the dplyr package to transform your data.\nSpecifically, you will learn how to explore, filter, reorganise and process a dataframe with the following verbs:\n\nselect(): pick variables\nfilter(): pick observations\narrange(): reorder observations\nmutate(): create new variables\nsummarise(): collapse to a single summary\ngroup_by(): change the scope of function",
    "crumbs": [
      "Workshops",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "Workshops/2 - Data processing.html#keep-in-mind",
    "href": "Workshops/2 - Data processing.html#keep-in-mind",
    "title": "Preparing data for analysis",
    "section": "Keep in mind",
    "text": "Keep in mind\n\nEverything we write today will be saved in your project. Please remember to save it somewhere you can access it later if you wish to revisit what we do today.\nR is case sensitive: it will tell the difference between uppercase and lowercase.\nRespect the naming rules for objects (no spaces, does not start with a number…)\n\n\nHelp\nFor any dataset or function doubts that you might have, don’t forget the three ways of getting help in RStudio:\n\nthe shortcut command: ?functionname\nthe help function: help(functionname)\nthe keyboard shortcut: press F1 after writing a function name",
    "crumbs": [
      "Workshops",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "Workshops/2 - Data processing.html#setting-up",
    "href": "Workshops/2 - Data processing.html#setting-up",
    "title": "Preparing data for analysis",
    "section": "Setting up",
    "text": "Setting up\n\nInstall the dplyr package\nIf you don’t have it already, you can install dplyr with the command: install.packages(\"dplyr\")\n\nAlternatively, you can install the whole “tidyverse”, a meta-package useful for data science: install.packages(\"tidyverse\")\n\n\n\nCreate a script\nWe will use a script to write code more comfortably.\n\nMenu: Top left corner, click the green “plus” symbol, or press the shortcut (for Windows/Linux) Ctrl+Shift+N or (for Mac) Cmd+Shift+N. This will open an “Untitled1” file.\nGo to “File &gt; Save” or press (for Windows/Linux) Ctrl+S or (for Mac) Cmd+S. This will ask where you want to save your file and the name of the new file.\nCall your file “process.R”\n\n\n\nIntroducing our data\nLet’s import and explore the gapminder data again.\n\nuse the read.csv() command to bring it into R:\n\ngapminder &lt;- read.csv(\"data/gapminder.csv\")\n\nRemember you can use Ctrl+shift to execute a command from the script.\n\n\nYou can explore the gapminder dataset using dim(), head() and str()\n\nHow can we get the dataframe’s variable names? There are two ways: names(gapminder) returns the names regardless of the object type, such as list, vector, data.frame etc., whereas colnames(gapminder) returns the variable names for matrix-like objects, such as matrices, dataframes…\nTo return one specific column in the dataframe, you can use the dollar syntax: gapminder$year. For example, try these:\nclass(gapminder$country) # what kind of data?\n[1] \"character\"\nrange(gapminder$year) # what is the time range?\n[1] 1952 2007",
    "crumbs": [
      "Workshops",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "Workshops/2 - Data processing.html#basic-dplyr-verbs",
    "href": "Workshops/2 - Data processing.html#basic-dplyr-verbs",
    "title": "Preparing data for analysis",
    "section": "Basic dplyr verbs",
    "text": "Basic dplyr verbs\nThe R package dplyr was developed by Hadley Wickham for data manipulation.\nThe book R for Data Science introduces the package as follows:\n\nYou are going to learn the five key dplyr functions that allow you to solve the vast majority of your data manipulation challenges:\n\nPick variables by their names with select()\nPick observations by their values with filter()\nReorder the rows with arrange()\nCreate new variables with functions of existing variables with mutate()\nCollapse many values down to a single summary with summarise()\n\nThese can all be used in conjunction with group_by() which changes the scope of each function from operating on the entire dataset to operating on it group-by-group. These six functions provide the main verbs for a language of data manipulation.\n\nTo use the verbs to their full extent, we will use pipes and logical operators, which we will introduce as we go.\nLet’s load the dplyr package to access its functions:\nlibrary(dplyr)\n\nYou only need to install a package once (with install.packages()), but you need to reload it every time you start a new R session (with library()).\n\n\n1. Pick variables with select()\nselect() allows us to pick variables (i.e. columns) from the dataset. For example, to only keep the data about year, country and GDP per capita:\ngap_small &lt;- select(gapminder, year, country, gdpPercap)\nThe first argument refers to the dataframe that is being transformed, and the following arguments are the columns you want to keep. Notice that it keeps the order you specified?\nYou can also rename columns in the same command:\ngap_small &lt;- select(gapminder, year, country, gdpPerPerson = gdpPercap)\nIf you have many variables but only want to remove a small number, it might be better to deselect instead of selecting. You can do that by using the - character in front of a variable name:\nnames(select(gapminder, -continent))\n[1] \"country\"   \"year\"      \"pop\"       \"lifeExp\"   \"gdpPercap\"\nThere are also a lot of helper functions to select columns according to a logic. For example, to only keep the columns that have “a” in their names:\nnames(select(gapminder, contains(\"a\")))\n[1] \"year\"      \"gdpPercap\"\n\n\n2. Pick observations with filter()\nThe filter() function allows use to pick observations depending on one or several conditions. But to be able to define these conditions, we need to learn about logical operators.\nLogical operators allow us to compare things. Here are some of the most important ones:\n\n==: equal\n!=: different or not equal\n&gt;: greater than\n&lt;: smaller than\n&gt;=: greater or equal\n&lt;=: smaller or equal\n\n\nRemember: = is used to pass on a value to an argument, whereas == is used to check for equality. Using = instead of == for a logical statment is one of the most common errors and R will give you a reminder in the console when this happens.\n\nFor example, to filter the observations for Australia, we can use the following condition:\naustralia &lt;- filter(gapminder, country == \"Australia\")\naustralia\n# A tibble: 12 × 6\n   country    year      pop continent lifeExp gdpPercap\n   &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n 1 Australia  1952  8691212 Oceania      69.1    10040.\n 2 Australia  1957  9712569 Oceania      70.3    10950.\n 3 Australia  1962 10794968 Oceania      70.9    12217.\n 4 Australia  1967 11872264 Oceania      71.1    14526.\n 5 Australia  1972 13177000 Oceania      71.9    16789.\n 6 Australia  1977 14074100 Oceania      73.5    18334.\n 7 Australia  1982 15184200 Oceania      74.7    19477.\n 8 Australia  1987 16257249 Oceania      76.3    21889.\n 9 Australia  1992 17481977 Oceania      77.6    23425.\n10 Australia  1997 18565243 Oceania      78.8    26998.\n11 Australia  2002 19546792 Oceania      80.4    30688.\n12 Australia  2007 20434176 Oceania      81.2    34435.\nThe function compares the value “Australia” to all the values in the country variable, and only keeps the rows that have TRUE as an answer.\nNow, let’s filter the rows that have a life expectancy lifeExp greater than 81 years:\nlife81 &lt;- filter(gapminder, lifeExp &gt; 81)\ndim(life81)\n[1] 7 6\n\n\n3. Reorder observations with arrange()\narrange() will reorder our rows according to a variable, by default in ascending order:\narrange(life81, lifeExp)\n# A tibble: 7 × 6\n  country          year       pop continent lifeExp gdpPercap\n  &lt;chr&gt;           &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1 Australia        2007  20434176 Oceania      81.2    34435.\n2 Hong Kong China  2002   6762476 Asia         81.5    30209.\n3 Switzerland      2007   7554661 Europe       81.7    37506.\n4 Iceland          2007    301931 Europe       81.8    36181.\n5 Japan            2002 127065841 Asia         82      28605.\n6 Hong Kong China  2007   6980412 Asia         82.2    39725.\n7 Japan            2007 127467972 Asia         82.6    31656.\nIf we want to have a look at the entries with highest life expectancy first, we can use the desc() function (for “descending”):\narrange(life81, desc(lifeExp))\n# A tibble: 7 × 6\n  country          year       pop continent lifeExp gdpPercap\n  &lt;chr&gt;           &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1 Japan            2007 127467972 Asia         82.6    31656.\n2 Hong Kong China  2007   6980412 Asia         82.2    39725.\n3 Japan            2002 127065841 Asia         82      28605.\n4 Iceland          2007    301931 Europe       81.8    36181.\n5 Switzerland      2007   7554661 Europe       81.7    37506.\n6 Hong Kong China  2002   6762476 Asia         81.5    30209.\n7 Australia        2007  20434176 Oceania      81.2    34435.\n\nThe pipe operator\nWhat if we wanted to get that result in one single command, without an intermediate life81 object?\nWe could nest the commands into each other, the first step as the first argument of the second step:\narrange(filter(gapminder, lifeExp &gt; 81), desc(lifeExp))\n… but this becomes very hard to read, very quickly. (Imagine with 3 steps or more!)\nWe can make our code more readable and avoid creating useless intermediate objects by piping commands into each other. The pipe operator %&gt;% strings commands together, using the left side’s output as the first argument of the right side function.\nFor example, this command:\ngapminder %&gt;%\n  filter(lifeExp &gt; 81) %&gt;% \n  arrange(desc(lifeExp))\n… is equivalent to:\narrange(filter(gapminder, lifeExp &gt; 81), desc(lifeExp))\nThe pipe operator can be read as “then” and makes the code a lot more readable than when nesting functions into each other, and avoids the creation of several intermediate objects. It is also easier to troubleshoot as it makes it easy to execute the pipeline step by step.\nFrom now on, we’ll use the pipe syntax as a default.\n\nNote that this material uses the magrittr pipe. The magrittr package is the one that introduced the pipe operator to the R world, and dplyr automatically imports this useful operator when it is loaded. However, the pipe being such a widespread and popular concept in programming and data science, it ended up making it into Base R (the “native” pipe) in 2021 with the release of R 4.1, using a different operator: |&gt;. You can switch your pipe shortcut to the native pipe in Tools &gt; Global options &gt; Code &gt; Use native pipe operator.\n\n\n\n\n4. Create new variables with mutate()\nHave a look at what the verb mutate() can do with ?mutate.\nLet’s see what the two following variables can be used for:\ngapminder %&gt;%\n    select(gdpPercap, pop)\n# A tibble: 1,704 × 2\n   gdpPercap      pop\n       &lt;dbl&gt;    &lt;dbl&gt;\n 1      779.  8425333\n 2      821.  9240934\n 3      853. 10267083\n 4      836. 11537966\n 5      740. 13079460\n 6      786. 14880372\n 7      978. 12881816\n 8      852. 13867957\n 9      649. 16317921\n10      635. 22227415\n# ℹ 1,694 more rows\nHow do you think we could combine them to add something new to our dataset?\nWe can use mutate() to create a gdp variable that tells us the total gdp.\nName your new dataset gap_gdp. When finished, dim(gap_gdp) should result in 1704 7.\nHint: use the * operator within mutate() to multiply the pop by gdpPercap.\ngap_gdp &lt;- gapminder %&gt;%\n    mutate(gdp = gdpPercap * pop)\ndim(gap_gdp)\n[1] 1704    7\nhead(gap_gdp)\n# A tibble: 6 × 7\n  country      year      pop continent lifeExp gdpPercap          gdp\n  &lt;chr&gt;       &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 Afghanistan  1952  8425333 Asia         28.8      779.  6567086330.\n2 Afghanistan  1957  9240934 Asia         30.3      821.  7585448670.\n3 Afghanistan  1962 10267083 Asia         32.0      853.  8758855797.\n4 Afghanistan  1967 11537966 Asia         34.0      836.  9648014150.\n5 Afghanistan  1972 13079460 Asia         36.1      740.  9678553274.\n6 Afghanistan  1977 14880372 Asia         38.4      786. 11697659231.\nYou can reuse a variable computed by ‘mutate()’ straight away. For example, we also want a more readable version of our new variable, in billion dollars:\ngap_gdp &lt;- gapminder %&gt;%\n    mutate(gdp = gdpPercap * pop,\n           gdpBil = gdp / 1e9)\n\n\n5. Collapse to a single value with summarise()\nsummarise() collapses many values down to a single summary. For example, to find the mean life expectancy for the whole dataset:\ngapminder %&gt;%\n  summarise(meanLE = mean(lifeExp))\n# A tibble: 1 × 1\n  meanLE\n   &lt;dbl&gt;\n1   59.5\nHowever, a single-value summary is not particularly interesting. summarise() becomes more powerful when used with group_by().\n\n\n6. Change the scope with group_by()\ngroup_by() changes the scope of the following function(s) from operating on the entire dataset to operating on it group-by-group.\nSee the effect of the grouping step:\ngapminder %&gt;%\n    group_by(continent)\n# A tibble: 1,704 × 6\n   country      year      pop continent lifeExp gdpPercap\n   &lt;chr&gt;       &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n 1 Afghanistan  1952  8425333 Asia         28.8      779.\n 2 Afghanistan  1957  9240934 Asia         30.3      821.\n 3 Afghanistan  1962 10267083 Asia         32.0      853.\n 4 Afghanistan  1967 11537966 Asia         34.0      836.\n 5 Afghanistan  1972 13079460 Asia         36.1      740.\n 6 Afghanistan  1977 14880372 Asia         38.4      786.\n 7 Afghanistan  1982 12881816 Asia         39.9      978.\n 8 Afghanistan  1987 13867957 Asia         40.8      852.\n 9 Afghanistan  1992 16317921 Asia         41.7      649.\n10 Afghanistan  1997 22227415 Asia         41.8      635.\n# ℹ 1,694 more rows\nThe data in the cells is the same, the size of the object is the same. However, the dataframe was converted to a tibble, because a dataframe is not capable of storing grouping information.\nUsing the group_by() function before summarising makes things more interesting. Let’s re-run the previous command, with the intermediate grouping step:\ngapminder %&gt;%\n  group_by(continent) %&gt;% \n  summarise(meanLE = mean(lifeExp))\n# A tibble: 5 × 2\n  continent meanLE\n  &lt;chr&gt;      &lt;dbl&gt;\n1 Africa      48.9\n2 Americas    64.7\n3 Asia        60.1\n4 Europe      71.9\n5 Oceania     74.3\nWe now have the summary computed for each continent.\nSimilarly, to find out the total population per continent in 2007, we can do the following:\ngapminder %&gt;% \n    filter(year == 2007) %&gt;%\n    group_by(continent) %&gt;%\n    summarise(pop = sum(pop))\n# A tibble: 5 × 2\n  continent        pop\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Africa     929539692\n2 Americas   898871184\n3 Asia      3811953827\n4 Europe     586098529\n5 Oceania     24549947",
    "crumbs": [
      "Workshops",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "Workshops/2 - Data processing.html#exporting-your-data",
    "href": "Workshops/2 - Data processing.html#exporting-your-data",
    "title": "Preparing data for analysis",
    "section": "Exporting your data",
    "text": "Exporting your data\nIf you want to save your data as a .csv file, you can use the write.csv() function:\npop07 &lt;- gapminder %&gt;% \n  filter(year == 2007) %&gt;%\n  group_by(continent) %&gt;%\n  summarise(pop = sum(pop))\n\nwrite.csv(pop07, \"pop07.csv\")\nYou can also use it with the pipe:\ngapminder %&gt;% \n  filter(year == 2007) %&gt;%\n  group_by(continent) %&gt;%\n  summarise(pop = sum(pop)) %&gt;%\n  write.csv(\"pop07.csv\")",
    "crumbs": [
      "Workshops",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "Workshops/2 - Data processing.html#more-examples",
    "href": "Workshops/2 - Data processing.html#more-examples",
    "title": "Preparing data for analysis",
    "section": "More examples",
    "text": "More examples\nAnother example of a summary, with a the starwars data set that dplyr provides:\nGrouping by species, summarise the number of characters per species and find the mean mass. Only for species groups with more than 1 character.\nstarwars %&gt;%\n  group_by(species) %&gt;%\n  summarise(\n    n = n(), # this counts the number of rows in each group\n    mass = mean(mass, na.rm = TRUE)\n  ) %&gt;%\n  filter(n &gt; 1) # the mean of a single value is not worth reporting\n# A tibble: 9 × 3\n  species      n  mass\n  &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;\n1 Droid        6  69.8\n2 Gungan       3  74  \n3 Human       35  81.3\n4 Kaminoan     2  88  \n5 Mirialan     2  53.1\n6 Twi'lek      2  55  \n7 Wookiee      2 124  \n8 Zabrak       2  80  \n9 &lt;NA&gt;         4  81  \nAn example of data manipulation and data visualisation in the same command with gapminder:\nSummarise the gapminder population data into total population per continent per year and plot coloured by continent.\n# increase in population per continent\nlibrary(ggplot2)\ngapminder %&gt;% \n  group_by(continent, year) %&gt;% \n  summarise(pop = sum(pop)) %&gt;% \n  ggplot(aes(x = year,\n             y = pop,\n             colour = continent)) +\n  geom_line()\n`summarise()` has grouped output by 'continent'. You can override using the\n`.groups` argument.\nAnd another example, using using our gapminder dataset:\nLet’s say we want to calulate the variation (range) in life expectancy per country and plot the top and bottom 10 countries?\ngapminder %&gt;% \n  group_by(country) %&gt;% \n  summarise(maxLifeExp = max(lifeExp),\n            minLifeExp = min(lifeExp)) %&gt;% \n  mutate(dif = maxLifeExp - minLifeExp) %&gt;%  # new col with difference betwen max/min lifeExp\n  arrange(desc(dif)) %&gt;%  # arrange by dif, descending order for the next step\n  slice(1:10, (nrow(.)-10):nrow(.)) %&gt;%  # slice top 10 rows and bottom 10 rows\n  ggplot(aes(x = reorder(country, dif), y = dif)) +\n  geom_col() +\n  coord_flip() + # flip the x and y axis for a horizontal bar chart\n  labs(x = \"Country\",\n       y = \"Difference in Life Expectancy\") + # prettier labels for axes (which have been flipped) \n  annotate(\"segment\", x = 11.5, xend = 21.5, y = 39, yend = 39, colour = \"purple\", size=1, alpha=0.6) +\n  annotate(\"segment\", x = 0.5, xend = 11, y = 39, yend = 39, colour = \"green\", size=1, alpha=0.6) +\n    annotate(\"text\", x = c(5, 16), y = c(40, 40), \n           label = c(\"Smallest 10\", \"Largest 10\") ,\n           color=\"black\", size= 5 , angle=90) # add labels to colored lines\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.",
    "crumbs": [
      "Workshops",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "Workshops/2 - Data processing.html#close-project",
    "href": "Workshops/2 - Data processing.html#close-project",
    "title": "Preparing data for analysis",
    "section": "Close project",
    "text": "Close project\nIf you want to close RStudio, make sure you save your script first.\nYou can then close the window, and if your script contains all the steps necessary for your data processing, it is safer to not save your workspace at the prompt. It should only take a second te execute all the commands stored in your script when you re-open your project.",
    "crumbs": [
      "Workshops",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "Workshops/4 - Sharing and Publishing.html",
    "href": "Workshops/4 - Sharing and Publishing.html",
    "title": "Sharing and Publishing",
    "section": "",
    "text": "In this workshop we cover using GitHub for sharing your source code, Git for version control, and Quarto for publishing outputs. Specifically, we look at:",
    "crumbs": [
      "Workshops",
      "Sharing and Publishing"
    ]
  },
  {
    "objectID": "Workshops/4 - Sharing and Publishing.html#quarto",
    "href": "Workshops/4 - Sharing and Publishing.html#quarto",
    "title": "Sharing and Publishing",
    "section": "Quarto",
    "text": "Quarto\nQuarto is a publishing system that allows creating documents, presentations, websites and dashboards that contain prose, code and code outputs. This means that such outputs can detail exactly what happened to the data, and outputs can be re-generated very quickly if, for example, the underlying dataset was updated, or if the analysis needs to change.\nLet’s create a document using some of the syntax we learned in previous sessions.\nUse “New File &gt; Quarto Document…” to create a .qmd file. The dialog that open allows us to change a few settings. Let’s give the title “Reproducible Output”, and untick “Use visual markdown editor” so we can learn about the syntax. Save the new file in your project directory.\nThis new .rmd script will be made of markdown text and code chunks. Code chunks can be inserted with the editor pane’s toolbar or the keyboard shortcut Ctrl+Alt+I.\nAt the top of our script, we need to include a header (also called “front matter”) that contains the document’s settings. We can start with:\n---\ntitle: Reproducible Output\nauthor: Your Name\ndate: 2025-01-01\n---\nThe rest of the document will be a mix of markdown-formatted prose and executable code chunks. For example:\n## Import the data\n\nLet's **import** the data:\n\n```{r}\nplayers &lt;- read.csv(\"data_sources/Players2024.csv\")\n```\n\n## Prepare the data\n\nRemove missing position and ensure **reasonable heights**:\n\n```{r}\nlibrary(dplyr)\nplayers &lt;- players %&gt;% filter(positions != \"Missing\", height_cm &gt; 100)\n```\n\n## Plot the data\n\nA boxplot of player **height by position**:\n\n```{r}\nlibrary(ggplot2)\nggplot(players, aes(x = positions, y = height_cm)) + \n  geom_boxplot() + \n  labs(x = \"Position\", y = \"Height (cm)\")\n```\nOutside the code chunks, we use the Markdown markup language to format the text. For example, using ## before some text defines a heading of level 2 (level 1 being the document’s title), and using ** around some text makes it bold. See more Markdown hints in the Quarto documentation.\n\nRendering\nTo render the document and see the result, use the “Render” button in the source pane toolbar.\nThis should create a HTML document in your project directory, which you can open in a web browser by clicking it and choosing “View in web browser” (if it is not opened automatically already). The file can be left open and will automatically update in your browser when the document is rendered again.\nAs the default Quarto output is a HTML file, we can include interactive visualisations too.\n\n\nCell options\nIf you want to show the code but don’t want to run it, you can add the cell option #| eval: false. And if you want to show the output but not show the underlying code, use #| echo: false.\n\n## Interactive plots\n\nWe need plotly. If you need to install it:\n\n```{r}\n#| eval: false\ninstall.packages(\"plotly\")\n```\n\nAn interactive scartterplot:\n\n```{r}\n#| title: Age vs Height\n#| echo: false\n\np &lt;- ggplot(players, aes(x = age, y = height_cm, colour = positions, label = name, label2 = nationality)) + \n  geom_point() + \n  facet_wrap(vars(positions)) + \n  labs(x = \"Age\", colour = \"Position\", y = \"Height (cm)\")\nlibrary(plotly)\nggplotly(p)\n```\nAnd for adding a caption and alternative text to a figure, we can modify our boxplot chunk as follows:\n```{r}\n#| fig-cap: \"Goalkeepers tend to be taller.\"\n#| fig-alt: \"A boxplot of the relationship between height and position.\"\nlibrary(ggplot2)\nggplot(players, aes(x = positions, y = height_cm)) + \n  geom_boxplot() + \n  labs(x = \"Position\", y = \"Height (cm)\")\n```\nMany more cell options exist, including captioning and formatting visualisations. Note that these options can be used at the cell level as well as globally (by modifying the front matter at the top of the document).\nFor example, to make sure error and warning messages are never shown:\n---\ntitle: Reproducible Output\nauthor: Your Name\ndate: 2025-01-01\nwarning: false\nerror: false\n---\n\n\nOutput formats\nThe default output format in Quarto is HTML, which is by far the most flexible. However, Quarto is a very versatile publishing system and can generate many different output formats, including PDF, DOCX and ODT, slide formats, Markdown suited for GitHub… and even whole blogs, books and dashboards.\nLet’s try rendering a PDF:\n---\ntitle: Reproducible Output\nauthor: Your Name\ndate: 2025-01-01\nformat: pdf\n---\nWhen rendering PDFs, the first issue we might run into is the lack of a LaTeX distribution. If Quarto didn’t detect one, it will suggest to install tinytex (a minimal LaTeX distribution) with this terminal command:\nquarto install tinytex\nOnce that is installed, Quarto should render a PDF.\nAnother issue with our example document is that an interactive HTML visualisation won’t be rendered in the PDF. You can suppress it by using the #| eval: false option:\n```{r}\n#| title: Age vs Height\n#| echo: false\n#| eval: false\np &lt;- ggplot(players, aes(x = age, y = height_cm, colour = positions, label = name, label2 = nationality)) + \n  geom_point() + \n  facet_wrap(vars(positions)) + \n  labs(x = \"Age\", colour = \"Position\", y = \"Height (cm)\")\nlibrary(plotly)\nggplotly(p)\n```\n\nDashboard\nA great way to present a variety of outputs in a grid is by creating a HTML dashboard.\nLet’s modify our script to render a dashboard. First, change the output format:\n---\ntitle: Reproducible Output\nauthor: Your Name\ndate: 2025-01-01\nformat: dashboard\n---\nWe can already render the dashboard and see the result. Each panel can be expanded with the bottom-right button. Note that by default:\n\neach cell is rendered in a separate card\nheadings define the rows\nthe heading text is discarded\ncode is not shown (but can be by using echo: true)\n\nGiven this default behaviour, you might have to rethink a good part of your script to make it suited for a striking dashboard. For example, removing most of the text, customising the layout (tabsets, rows, card heights…) and adding custom cards like “value boxes”. Learn more about all these in the Quarto Dashboards documentation.\nAs a starting point, copy the current script across to a new script called dashboard.rmd and modify it so it matches the following:\n---\ntitle: \"My dashboard\"\nauthor: Your Name\ndate: 2025-01-01\nformat: dashboard\nwarning: false\n---\n\n```{r}\nplayers &lt;- read.csv(\"data_sources/Players2024.csv\")\n```\n\n```{r}\nlibrary(dplyr)\nplayers &lt;- players %&gt;% filter(positions != \"Missing\", height_cm &gt; 100)\n```\n\n## Figures {height=70%}\n\n```{r}\n#| title: Goalkeepers tend to be taller\n#| fig-alt: \"A boxplot of the relationship between height and position.\"\nlibrary(ggplot2)\nggplot(players, aes(x = positions, y = height_cm)) + \n  geom_boxplot() + \n  labs(x = \"Position\", y = \"Height (cm)\")\n```\n\n```{r}\n#| title: Age vs Height by position\np &lt;- ggplot(players, aes(x = age, y = height_cm, colour = positions, label = name, label2 = nationality)) + \n  geom_point() + \n  facet_wrap(vars(positions)) + \n  labs(x = \"Age\", colour = \"Position\", y = \"Height (cm)\")\nlibrary(plotly)\nggplotly(p)\n```\n\n## Table\n\n```{r}\n#| title: A glimpse at the dataset\nlibrary(knitr)\nkable(players)\n```\nThis results in a dashboard containing three cards organised in two rows. The top row uses 70% of the available height, and the bottom row shows a table of the top 10 rows of the dataset. Each card has a title.\n\n\n\nQuarto dashboard with three cards: static visualisation, interactive visualisation, and table.",
    "crumbs": [
      "Workshops",
      "Sharing and Publishing"
    ]
  },
  {
    "objectID": "Workshops/4 - Sharing and Publishing.html#git-and-github",
    "href": "Workshops/4 - Sharing and Publishing.html#git-and-github",
    "title": "Sharing and Publishing",
    "section": "Git and GitHub",
    "text": "Git and GitHub\nGit is a version control system that allows to record a clean history of your project, track precise authorship, and collaborate asynchronously with others. It can be used offline, from the command line or with integration into Itegrated Desktop Environments (like RStudio, VS Code… Unfortunately, Spyder does not have Git integration).\nGitHub is one of many websites that allow you to host projects that are tracked with Git. But even without using Git at all, it is possible to use GitHub to share and make your project public. Many researchers use it to make their code public alongside a published paper, to increase reproducibility and transparency. It can also be useful to build and share a portfolio of your work.\nLearning about the ins and out of Git takes time, so in this section we will mainly use GitHub as a place to upload and share your code and outputs, and as a starting point for learning more about Git in the future.\n\nGitHub\nGitHub is currently the most popular place for hosting, sharing and collaborating on code. You can create an account for free, and then create a repository for your project.\n\nCreate an account and log in\nClick on the “+” button (top right of the page)\nSelect “New repository”\nChoose a name and description for your repository\nTick “Add a README file” - this will be where you introduce your project\nClick “Create repository”\n\nFrom there, you can upload your files, and edit text-based files straight from your web browser if you need to.\nThe README file is a markdown file that can contain the most important information about your project. It’s important to populate it as it is the first document most people see. It could contain:\n\nName and description of the project\nHow to use it (installation process if any, examples…)\nWho is the author, who maintains it\nHow to contribute\n\nFor inspiration, see the pandas README file.\nTo practice managing a git repository on GitHub, try creating a personal portfolio repository where you can showcase what you have worked on and the outputs your are most proud of.",
    "crumbs": [
      "Workshops",
      "Sharing and Publishing"
    ]
  },
  {
    "objectID": "Workshops/4 - Sharing and Publishing.html#further-resources",
    "href": "Workshops/4 - Sharing and Publishing.html#further-resources",
    "title": "Sharing and Publishing",
    "section": "Further resources",
    "text": "Further resources\n\nSome alternatives to GitHub: Codeberg and Gitlab\nQuarto documentation\nCourse on Git from the command line\nCourse on Git with GitHub\nBook on Git for R and RStudio users, by Jenny Bryan",
    "crumbs": [
      "Workshops",
      "Sharing and Publishing"
    ]
  },
  {
    "objectID": "Workshops/6 - Programming.html",
    "href": "Workshops/6 - Programming.html",
    "title": "Programming Essentials",
    "section": "",
    "text": "In this workshop we cover the building blocks for developing more complex code, looking at",
    "crumbs": [
      "Workshops",
      "Programming Essentials"
    ]
  },
  {
    "objectID": "Workshops/6 - Programming.html#directing-traffic-with-conditionals",
    "href": "Workshops/6 - Programming.html#directing-traffic-with-conditionals",
    "title": "Programming Essentials",
    "section": "Directing traffic with conditionals",
    "text": "Directing traffic with conditionals\nIn the first half of this session we’ll look at two types of control flows: conditionals and loops.\nConditionals allow you to put “gates” in your code, only running sections if a certain condition is true. They are common to most programming languages.\nIn R, they are called if statements, because you use the if command. For example,\n\nif (5 &gt; 0) {\n  print(\"We're inside the if statement\")\n}\n\n[1] \"We're inside the if statement\"\n\n\nThe line print(\"We're inside the if statement\") will only run if 5 &gt; 0 is true. If not, it’ll get skipped.\nCurly brackets are essential. Only code inside them will be governed by conditional\n\nif (5 &gt; 0) {\n  print(\"We're inside the if statement\")\n}\n\n[1] \"We're inside the if statement\"\n\nprint(\"This code always runs\")\n\n[1] \"This code always runs\"\n\n\nWatch what happens if we change the condition\n\nif (5 &gt; 10) {\n  print(\"We're inside the if statement\")\n}\n\nprint(\"This code always runs\")\n\n[1] \"This code always runs\"\n\n\nNow, the first line doesn’t run. That’s the essence of a conditional.\nThere’s not much point to using a condition that will always be true. Typically, you’d use a variable in the condition, for example.\n\npet_age &lt;- 10\n\nif (pet_age &gt; 10) {\n  print(\"My pet is older than 10\")\n}\n\n\nLogical operators\nHere is a table of the different operators you can make conditions with. When you run them, they always return either True or False.\n\n\n\n\n\n\n\n\nOperator\nTrue example\nDescription\n\n\n\n\n==\n10 == 10\nSame value and type\n\n\n!=\n\"10\" != 10\nDifferent value or type\n\n\n&gt;\n10 &gt; 5\nGreater than\n\n\n&gt;=\n10 &gt;= 10\nGreater than or equal to\n\n\n&lt;\n5 &lt; 10\nLess than\n\n\n&lt;=\n5 &lt;= 10\nLess than or equal to\n\n\n&&\n10 == 10 && \"apple\" == \"apple\"\nOnly true if both conditions are true.\n\n\n||\n10 == 10 || \"a\" == \"b\"\nAlways true if one condition is true.\n\n\n\n\n\nelif and else\nif statements only run if the condition is True. What happens if its False? That’s what the else command is for, it’s like a net that catches anything that slipped past if:\n\npet_age &lt;- 5\n\nif (pet_age &gt; 10) {\n  print(\"My pet is older than 10\")\n} else {\n  print(\"My pet is 10 or younger\")\n}\n\n[1] \"My pet is 10 or younger\"\n\n\n\nelse also needs curly brackets!\n\nCheck what happens when you change the age from 5 to 15.\nFinally, what if you wanted to check another condition only if the first one fails? That’s what else if is for. It’s another if statement but it only runs if the first fails.\n\npet_age = 5\n\nif (pet_age &gt; 10) {\n  print(\"My pet is older than 10\")\n} else if (pet_age &lt; 5) {\n  print(\"My pet is younger than 5\")\n} else {\n  print(\"My pet is 10 or younger\")\n}\n\n[1] \"My pet is 10 or younger\"\n\n\nYou can include as many as you’d like\n\npet_age = 5\n\nif (pet_age &gt; 10) {\n  print(\"My pet is older than 10\")\n} else if (pet_age &lt; 5) {\n  print(\"My pet is younger than 5\")\n} else if (pet_age &lt; 1) {\n  print(\"My pet is freshly born\")\n} else {\n  print(\"My pet is 10 or younger\")\n}\n\n[1] \"My pet is 10 or younger\"",
    "crumbs": [
      "Workshops",
      "Programming Essentials"
    ]
  },
  {
    "objectID": "Workshops/6 - Programming.html#repeat-after-me",
    "href": "Workshops/6 - Programming.html#repeat-after-me",
    "title": "Programming Essentials",
    "section": "Repeat after me",
    "text": "Repeat after me\nSometimes you need to repeat a task multiple times. Sometimes hundreds. Maybe you need to loop through 1 million pieces of data. Not fun.\nR’s loops offer us a way to run a section of code multiple times. There are two types: for loops, which run the code once for each element in a sequence (like a list or string), and while loops, which run until some condition is false.\n\nwhile loops\nThese are almost the same as if statements, except for the fact that they run the code multiple times. Let’s begin with a basic conditional\n\nnumber &lt;- 1\n\nif (number &lt; 5) {\n  paste(number, \"is less than 10.\")\n}\n\n[1] \"1 is less than 10.\"\n\n\n\nThe paste function lets you print multiple things together\n\nWhat if we wanted to check all the numbers between 5 and 10? We can use a while loop.\n\nnumber &lt;- 1\n\nwhile (number &lt; 5) {\n  print(paste(number, \"is less than 10.\"))\n  number &lt;- number + 1\n}\n\n[1] \"1 is less than 10.\"\n[1] \"2 is less than 10.\"\n[1] \"3 is less than 10.\"\n[1] \"4 is less than 10.\"\n\n\n\nWe need to include paste inside print because we’re doing it multiple times.\n\nWe’ve done two things\n\nReplace if with while\nIntroduce number = number + 1 to increase the number each time.\n\n\nWithout step 2, we’d have an infinite loop – one that never stops, because the condition would always be true!\n\nWhile loops are useful for repeating code an indeterminate number of times.\n\n\nfor loops\nRealistically, you’re most likely to use a for loop. They’re inherently safer (you can’t have an infinite loop) and often handier.\nIn R, for loops iterate through a sequence, like the objects in a list. This is more like other languages’ foreach, than most’s for.\nLet’s say you have a vector of different fruit\n\nlist_of_fruits &lt;- c(\"apple\", \"banana\", \"cherry\")\n\nand you want to run a section of code on \"apple\", then \"banana\", then \"cherry\". Maybe you want to know which ones have the letter “a”. We can start with a for loop\n\nlist_of_fruits &lt;- c(\"apple\", \"banana\", \"cherry\")\n\nfor (fruit in list_of_fruits) {\n  print(fruit)\n}\n\n[1] \"apple\"\n[1] \"banana\"\n[1] \"cherry\"\n\n\nThis loop’s job is to print out the variable fruit. But where is fruit defined? Well, the for loop runs print(fruit) for every element of list_of_fruits, storing the current element in the variable fruit. If we were to write it out explicitly, it would look like\n\nfruit &lt;- list_of_fruits[0]\nprint(fruit)\n\ncharacter(0)\n\nfruit &lt;- list_of_fruits[1]\nprint(fruit)\n\n[1] \"apple\"\n\nfruit &lt;- list_of_fruits[2]\nprint(fruit)\n\n[1] \"banana\"\n\n\nLet’s return to our goal: working out which ones have an “a”. We need to put a conditional inside the loop:\n\nlist_of_fruits &lt;- c(\"apple\", \"banana\", \"cherry\")\n\nfor (fruit in list_of_fruits) {\n    if (grepl(\"a\", fruit)) { \n      print(paste(\"a is in\", fruit))\n    }\n    else {\n      print(paste(\"a is not in\", fruit))\n    }\n}\n\n[1] \"a is in apple\"\n[1] \"a is in banana\"\n[1] \"a is not in cherry\"\n\n\nFinally, it’s often convenient to loop through a list of numbers. R makes this easy with the x:y notation:\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\ncontains all the integers between \\(1\\) and \\(10\\). To loop through each,\n\nfor (i in 1:10) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n\n\nThe advantage of this approach is that we can loop through many numbers:\n\nfor (i in 1:1000) {\n  print(i)\n}\n\nThis can be useful if you need to loop through multiple objects by indexing. We’ll spare you the output here.\n\n\nMapping with purrr\nConsider the follow situation. You have a dataset, and want to apply a function to every column. Or maybe some columns. What to do?\nYou could loop over them with a for loop. Alternatively, you could use the mapping functions in purrr, which simplifies the code.\nWhat is a map? Generally, a map takes something and makes it something else. So far, that’s the same a function. The difference is that a map takes lots of things and translates them all in the same way. For example, a geographical map takes life-sized locations and transforms them all in the same way to a hand-sized piece of paper.\nEssentially, maps are a way of transforming a selection of variables in the same way. We’ll start by brining in the purrr library\n\nlibrary(purrr)\n\nLet’s use the same data as in the statistics session:\n\nlibrary(dplyr)\nplayers &lt;- read.csv(\"data/Players2024.csv\")\nplayers &lt;- players %&gt;% filter(positions != \"Missing\", height_cm &gt; 100)\n\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nWhat if you want the median value from all columns? We can use the map_dbl() function to map doubles (long decimal numbers):\n\nmap_dbl(players, median)\n\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\n\n\n       name  birth_date   height_cm   positions nationality         age \n         NA          NA         183          NA          NA          25 \n       club \n         NA \n\n\nDon’t worry about the warnings - they’re just there because you can’t take the median of a non-numeric variable. To check which ones are, we can map the logical operator is.numeric:\n\nmap_lgl(players, is.numeric)\n\n       name  birth_date   height_cm   positions nationality         age \n      FALSE       FALSE        TRUE       FALSE       FALSE        TRUE \n       club \n      FALSE \n\n\nWe can use the pipe here,\n\nplayers %&gt;% map_lgl(is.numeric)\n\n       name  birth_date   height_cm   positions nationality         age \n      FALSE       FALSE        TRUE       FALSE       FALSE        TRUE \n       club \n      FALSE \n\n\nLet’s select the numeric columns and look at the medians again\n\nplayers %&gt;% \n  select_if(is.numeric) %&gt;%\n  map_dbl(median)\n\nheight_cm       age \n      183        25 \n\n\nWe can also create custom functions. We use .x to refer to the variable:\n\nplayers %&gt;% \n  select_if(is.numeric) %&gt;%\n  map_dbl(~max(.x) - min(.x))\n\nheight_cm       age \n       46        27",
    "crumbs": [
      "Workshops",
      "Programming Essentials"
    ]
  },
  {
    "objectID": "Workshops/6 - Programming.html#building-your-own-machines",
    "href": "Workshops/6 - Programming.html#building-your-own-machines",
    "title": "Programming Essentials",
    "section": "Building your own machines",
    "text": "Building your own machines\nWe’ll wrap this session up by looking at custom functions. So far, we’ve only used built-in functions or those from other people’s modules. But we can make our own!\nWe’ve only ever called functions - this is what we do when we use them. All functions need a definition, this is the code that gets run when they’re called.\n\nThe function definition\nFunctions are machines. They take some inputs, run some code with those inputs, and spit out one output. We need to define how they work before we use them. We should specify\n\nA name\nSome inputs\nThe code to run (the machine itself)\n\nWe include these in three steps\n\nThe first line of the function definition (the function signature) specifies the name and inputs\nWe then indent all the code we want to run with our inputs\nWe end with a return statement, specifying the output\n\n\ninsert_function_name_here &lt;- function(input_1_name, input_2_name, ...) {\n  # Code code code\n}\n\nFor example, let’s create a function that converts centimetres to metres.\n\ncm_to_m &lt;- function(value_in_cm) {\n    value_in_cm / 100\n}\n\nTaking it apart, we have\n\nName: cm_to_m\nInputs (just one): value_in_cm\nCode (just one line): value_in_cm / 100\n\nImportantly, nothing appears when you run this code. Why? Because you’ve only defined the function, you haven’t used it yet.\nTo use this function, we need to call it. Let’s convert \\(10\\text{ cm}\\) to \\(\\text{m}\\).\n\ncm_to_m &lt;- function(value_in_cm) {\n    value_in_cm / 100\n}\n\ncm_to_m(10)\n\n[1] 0.1\n\n\nWhen we call the function, it runs with value_in_cm &lt;- 10.\nThat’s it! Every function that you use, built-in or imported, looks like this.\nBecause functions must be defined before called, and defining them produces no output, best practice is to place functions at the top of your script, below the import statements.\n\nReturn values and default values\nOne quirk of R functions is that, by default, they return the output of the line. Let’s add a new line that prints the message “\\(x\\text{ cm} = y\\text{ m}\\)”. We’ll need to also save our calculation in the process:\n\ncm_to_m &lt;- function(value_in_cm) {\n    value_in_m &lt;- value_in_cm / 100\n    print(paste(value_in_cm, \"cm =\", value_in_m, \"m\"))\n}\n\ncm_to_m(10)\n\n[1] \"10 cm = 0.1 m\"\n\n\nIt works, but we have a problem. The output of the function is the whole message, not the value. The easiest way to fix this is to call the output on the last line:\n\ncm_to_m &lt;- function(value_in_cm) {\n    value_in_m &lt;- value_in_cm / 100\n    print(paste(value_in_cm, \"cm =\", value_in_m, \"m\"))\n    value_in_m\n}\n\ncm_to_m(10)\n\n[1] \"10 cm = 0.1 m\"\n\n\n[1] 0.1\n\n\nAlternatively, you can use the return() function to exit before the end and manually specify the output.",
    "crumbs": [
      "Workshops",
      "Programming Essentials"
    ]
  },
  {
    "objectID": "Projects/datasets.html",
    "href": "Projects/datasets.html",
    "title": "Datasets and tips",
    "section": "",
    "text": "We have nine datasets for you to choose from. We recommend saving your data inside your project.\n\n\n\nDataset\nDescription\n\n\n\n\nWorld populations\nA summary of world populations and corresponding statistics\n\n\nSoccer players\nA summary of 2024 soccer players\n\n\nCoffee survey\nA survey of coffee preferences\n\n\nGapminder\nGDP and life expectancy data by country\n\n\nMelbourne housing data\nA collection of houses for sale in Melbourne. See here for variable explanations\n\n\nGoodreads books\nData from Goodreads books\n\n\nQueensland hospitals\nEmergency department statistics. See here for source and details.\n\n\nQueensland fuel prices\nFuel prices by the pump in Queensland\n\n\nAeroplane bird strikes\nAeroplane bird strike incidents fron the 90s",
    "crumbs": [
      "Workshops",
      "The Project",
      "Datasets and tips"
    ]
  },
  {
    "objectID": "Projects/datasets.html#datasets",
    "href": "Projects/datasets.html#datasets",
    "title": "Datasets and tips",
    "section": "",
    "text": "We have nine datasets for you to choose from. We recommend saving your data inside your project.\n\n\n\nDataset\nDescription\n\n\n\n\nWorld populations\nA summary of world populations and corresponding statistics\n\n\nSoccer players\nA summary of 2024 soccer players\n\n\nCoffee survey\nA survey of coffee preferences\n\n\nGapminder\nGDP and life expectancy data by country\n\n\nMelbourne housing data\nA collection of houses for sale in Melbourne. See here for variable explanations\n\n\nGoodreads books\nData from Goodreads books\n\n\nQueensland hospitals\nEmergency department statistics. See here for source and details.\n\n\nQueensland fuel prices\nFuel prices by the pump in Queensland\n\n\nAeroplane bird strikes\nAeroplane bird strike incidents fron the 90s",
    "crumbs": [
      "Workshops",
      "The Project",
      "Datasets and tips"
    ]
  },
  {
    "objectID": "Projects/datasets.html#tips",
    "href": "Projects/datasets.html#tips",
    "title": "Datasets and tips",
    "section": "Tips",
    "text": "Tips\nHere’s a few general tips. In addition, we strongly recommend using popular cheatsheets, which give a quick and easy reference for common packages and functions, and from Data to Viz, which guides you through choosing a visualisation.\n\nHotkeys\n\n\n\n\n\n\n\n\nCode\nHotkey\nDescription\n\n\n\n\n\nCtrl+Enter\nRun current line (when in Script)\n\n\n&lt;-\nAlt+Enter\nAssignment\n\n\n%&gt;%\nCtrl+Shift+M\nPipe\n\n\n\nEsc\nCancel current operation (when in Console)\n\n\n\nF1\nHelp documentation for selected function\n\n\n\n\n\nData manipulation\n\nImporting and exporting data\nIn case you’ve forgotten, use the read.csv() function to import data:\ndataset &lt;- read.csv(\"data/dataset.csv\")\nIf you’d like to export any files from R to “.csv”, use write.csv()\nwrite.csv(dataset, \"data/output_name.csv\")\n\n\nInitial exploration\nYou’ll want to explore the data to start with - below are a few functions to get started.\n\n\n\n\n\n\n\n\nFunction\nExample\nDescription\n\n\n\n\nnames()\nnames(dataset)\nReturns the variable names\n\n\nstr()\nstr(dataset)\nReturns the structure of the dataset (variable names, types and first entries)\n\n\n$\ndataset$variable\nReturns a specific variable\n\n\nunique()\nunique(dataset$variable)\nReturns the unique values of a variable\n\n\nsummary()\nsummary(dataset$variable)\nReturns a statistical summary of a variable\n\n\n\n\n\nRemoving NAs\nWe can use the dplyr package to remove rows which have NA:\nlibrary(dplyr)\n\ndataset &lt;- dataset %&gt;%\n  filter(!is.na(variable_to_check_for_NAs))\n\nWe use the exclamation mark ! to negate the result, because is.na returns all the rows that are NA.\n\n\n\nTime series data\nIf you’ve picked a dataset with time-series data (e.g. a “date” variable), you should transform that variable so that it visualises better:\ndataset$variable &lt;- as.Date(dataset$variable)\n\n\nCategorical and ordered data\nIf you’re dealing with categorical data, it can be helpful to tell R that it has levels:\ndataset$variable &lt;- factor(dataset$variable)\nTo manually specify the order to R, send in an ordered list of the levels joined with c():\ndataset$variable &lt;- factor(dataset$variable, levels = c(\"first_val\", \"second_val\", ... ))\n\nThis is particularly useful for the Coffee survey dataset.\n\nAlternatively, if you only need to specify the first (reference) level, use\ndataset$variable &lt;- factor(dataset$variable)\ndataset$variable &lt;- relevel(dataset$variable, ref = \"reference_level\")\n\n\nRenaming variables\nSome datasets have cumbersome names for their variables. We can change variable names with\ndf &lt;- df %&gt;% \n  rename(new_name = old_name)\n\nThis is particularly useful for the World population dataset.\n\n\n\n\nVisualisation\nWe use the ggplot() function with geometries to create visualisations\nlibrary(ggplot2)\n\nggplot(data = dataset,\n       mapping = aes(x = ..., y = ..., colour = ..., ...)) +\n  geom_first_layer() + \n  geom_second_layer() + \n  ...\nTake a look at the ggplot2 documentation for more information.\n\nPlotly workaround\nIf you’re having issues using ggplotly (it’s producing a blank plot), you can use this workaround to view it in your browser.\nplot &lt;- ggplotly(saved_ggplot_image)\nhtmlwidgets::saveWidget(as_widget(plot), \"plots/name_of_plot.html\")\nOpening that file will show you the image.",
    "crumbs": [
      "Workshops",
      "The Project",
      "Datasets and tips"
    ]
  }
]